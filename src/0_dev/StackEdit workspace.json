{"3Onhrwns2UKPGrmE":{"id":"3Onhrwns2UKPGrmE","type":"file","name":"Welcome file","parentId":null,"hash":-585715289,"tx":1},"templates":{"id":"templates","type":"data","data":{},"hash":-972705388,"tx":15},"3Onhrwns2UKPGrmE/content":{"id":"3Onhrwns2UKPGrmE/content","type":"content","text":"# Welcome to StackEdit!\n\nHi! I'm your first Markdown file in **StackEdit**. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the **file explorer** on the left corner of the navigation bar.\n\n\n# Files\n# files\nStackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible **offline!**\n\n## Create files and folders\n\nThe file explorer is accessible using the button in left corner of the navigation bar. You can create a new file by clicking the **New file** button in the file explorer. You can also create folders by clicking the **New folder** button.\n\n## Switch to another file\n\nAll your files and folders are presented as a tree in the file explorer. You can switch from one to another by clicking a file in the tree.\n\n## Rename a file\n\nYou can rename the current file by clicking the file name in the navigation bar or by clicking the **Rename** button in the file explorer.\n\n## Delete a file\n\nYou can delete the current file by clicking the **Remove** button in the file explorer. The file will be moved into the **Trash** folder and automatically deleted after 7 days of inactivity.\n\n## Export a file\n\nYou can export the current file by clicking **Export to disk** in the menu. You can choose to export the file as plain Markdown, as HTML using a Handlebars template or as a PDF.\n\n\n# Synchronization\n\nSynchronization is one of the biggest features of StackEdit. It enables you to synchronize any file in your workspace with other files stored in your **Google Drive**, your **Dropbox** and your **GitHub** accounts. This allows you to keep writing on other devices, collaborate with people you share the file with, integrate easily into your workflow... The synchronization mechanism takes place every minute in the background, downloading, merging, and uploading file modifications.\n\nThere are two types of synchronization and they can complement each other:\n\n- The workspace synchronization will sync all your files, folders and settings automatically. This will allow you to fetch your workspace on any other device.\n\t> To start syncing your workspace, just sign in with Google in the menu.\n\n- The file synchronization will keep one file of the workspace synced with one or multiple files in **Google Drive**, **Dropbox** or **GitHub**.\n\t> Before starting to sync files, you must link an account in the **Synchronize** sub-menu.\n\n## Open a file\n\nYou can open a file from **Google Drive**, **Dropbox** or **GitHub** by opening the **Synchronize** sub-menu and clicking **Open from**. Once opened in the workspace, any modification in the file will be automatically synced.\n\n## Save a file\n\nYou can save any file of the workspace to **Google Drive**, **Dropbox** or **GitHub** by opening the **Synchronize** sub-menu and clicking **Save on**. Even if a file in the workspace is already synced, you can save it to another location. StackEdit can sync one file with multiple locations and accounts.\n\n## Synchronize a file\n\nOnce your file is linked to a synchronized location, StackEdit will periodically synchronize it by downloading/uploading any modification. A merge will be performed if necessary and conflicts will be resolved.\n\nIf you just have modified your file and you want to force syncing, click the **Synchronize now** button in the navigation bar.\n\n> **Note:** The **Synchronize now** button is disabled if you have no file to synchronize.\n\n## Manage file synchronization\n\nSince one file can be synced with multiple locations, you can list and manage synchronized locations by clicking **File synchronization** in the **Synchronize** sub-menu. This allows you to list and remove synchronized locations that are linked to your file.\n\n\n# Publication\n\nPublishing in StackEdit makes it simple for you to publish online your files. Once you're happy with a file, you can publish it to different hosting platforms like **Blogger**, **Dropbox**, **Gist**, **GitHub**, **Google Drive**, **WordPress** and **Zendesk**. With [Handlebars templates](http://handlebarsjs.com/), you have full control over what you export.\n\n> Before starting to publish, you must link an account in the **Publish** sub-menu.\n\n## Publish a File\n\nYou can publish your file by opening the **Publish** sub-menu and by clicking **Publish to**. For some locations, you can choose between the following formats:\n\n- Markdown: publish the Markdown text on a website that can interpret it (**GitHub** for instance),\n- HTML: publish the file converted to HTML via a Handlebars template (on a blog for example).\n\n## Update a publication\n\nAfter publishing, StackEdit keeps your file linked to that publication which makes it easy for you to re-publish it. Once you have modified your file and you want to update your publication, click on the **Publish now** button in the navigation bar.\n\n> **Note:** The **Publish now** button is disabled if your file has not been published yet.\n\n## Manage file publication\n\nSince one file can be published to multiple locations, you can list and manage publish locations by clicking **File publication** in the **Publish** sub-menu. This allows you to list and remove publication locations that are linked to your file.\n\n\n# Markdown extensions\n\nStackEdit extends the standard Markdown syntax by adding extra **Markdown extensions**, providing you with some nice features.\n\n> **ProTip:** You can disable any **Markdown extension** in the **File properties** dialog.\n\n\n## SmartyPants\n\nSmartyPants converts ASCII punctuation characters into \"smart\" typographic punctuation HTML entities. For example:\n\n|                |ASCII                          |HTML                         |\n|----------------|-------------------------------|-----------------------------|\n|Single backticks|`'Isn't this fun?'`            |'Isn't this fun?'            |\n|Quotes          |`\"Isn't this fun?\"`            |\"Isn't this fun?\"            |\n|Dashes          |`-- is en-dash, --- is em-dash`|-- is en-dash, --- is em-dash|\n\n\n## KaTeX\n\nYou can render LaTeX mathematical expressions using [KaTeX](https://khan.github.io/KaTeX/):\n\nThe *Gamma function* satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral\n\n$$\n\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.\n$$\n\n> You can find more information about **LaTeX** mathematical expressions [here](http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference).\n\n\n## UML diagrams\n\nYou can render UML diagrams using [Mermaid](https://mermaidjs.github.io/). For example, this will produce a sequence diagram:\n\n```mermaid\nsequenceDiagram\nAlice ->> Bob: Hello Bob, how are you?\nBob-->>John: How about you John?\nBob--x Alice: I am good thanks!\nBob-x John: I am good thanks!\nNote right of John: Bob thinks a long<br/>long time, so long<br/>that the text does<br/>not fit on a row.\n\nBob-->Alice: Checking with John...\nAlice->John: Yes... John, how are you?\n```\n\nAnd this will produce a flow chart:\n\n```mermaid\ngraph LR\nA[Square Rect] -- Link text --> B((Circle))\nA --> C(Round Rect)\nB --> D{Rhombus}\nC --> D\n```\n","properties":"\n","discussions":{},"comments":{},"hash":-131821423,"tx":25},"Nxop4XKtLamIHaeN":{"id":"Nxop4XKtLamIHaeN","type":"file","name":"Modelos -intro","parentId":null,"hash":-1618910401,"tx":37},"ngEhJlO2HTEBESzH":{"id":"ngEhJlO2HTEBESzH","type":"file","name":"how tfjs works","parentId":null,"hash":1423641658,"tx":37},"3Onhrwns2UKPGrmE/syncedContent":{"id":"3Onhrwns2UKPGrmE/syncedContent","type":"syncedContent","historyData":{"-131821423":{"id":"3Onhrwns2UKPGrmE/content","type":"content","text":"# Welcome to StackEdit!\n\nHi! I'm your first Markdown file in **StackEdit**. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the **file explorer** on the left corner of the navigation bar.\n\n\n# Files\n# files\nStackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible **offline!**\n\n## Create files and folders\n\nThe file explorer is accessible using the button in left corner of the navigation bar. You can create a new file by clicking the **New file** button in the file explorer. You can also create folders by clicking the **New folder** button.\n\n## Switch to another file\n\nAll your files and folders are presented as a tree in the file explorer. You can switch from one to another by clicking a file in the tree.\n\n## Rename a file\n\nYou can rename the current file by clicking the file name in the navigation bar or by clicking the **Rename** button in the file explorer.\n\n## Delete a file\n\nYou can delete the current file by clicking the **Remove** button in the file explorer. The file will be moved into the **Trash** folder and automatically deleted after 7 days of inactivity.\n\n## Export a file\n\nYou can export the current file by clicking **Export to disk** in the menu. You can choose to export the file as plain Markdown, as HTML using a Handlebars template or as a PDF.\n\n\n# Synchronization\n\nSynchronization is one of the biggest features of StackEdit. It enables you to synchronize any file in your workspace with other files stored in your **Google Drive**, your **Dropbox** and your **GitHub** accounts. This allows you to keep writing on other devices, collaborate with people you share the file with, integrate easily into your workflow... The synchronization mechanism takes place every minute in the background, downloading, merging, and uploading file modifications.\n\nThere are two types of synchronization and they can complement each other:\n\n- The workspace synchronization will sync all your files, folders and settings automatically. This will allow you to fetch your workspace on any other device.\n\t> To start syncing your workspace, just sign in with Google in the menu.\n\n- The file synchronization will keep one file of the workspace synced with one or multiple files in **Google Drive**, **Dropbox** or **GitHub**.\n\t> Before starting to sync files, you must link an account in the **Synchronize** sub-menu.\n\n## Open a file\n\nYou can open a file from **Google Drive**, **Dropbox** or **GitHub** by opening the **Synchronize** sub-menu and clicking **Open from**. Once opened in the workspace, any modification in the file will be automatically synced.\n\n## Save a file\n\nYou can save any file of the workspace to **Google Drive**, **Dropbox** or **GitHub** by opening the **Synchronize** sub-menu and clicking **Save on**. Even if a file in the workspace is already synced, you can save it to another location. StackEdit can sync one file with multiple locations and accounts.\n\n## Synchronize a file\n\nOnce your file is linked to a synchronized location, StackEdit will periodically synchronize it by downloading/uploading any modification. A merge will be performed if necessary and conflicts will be resolved.\n\nIf you just have modified your file and you want to force syncing, click the **Synchronize now** button in the navigation bar.\n\n> **Note:** The **Synchronize now** button is disabled if you have no file to synchronize.\n\n## Manage file synchronization\n\nSince one file can be synced with multiple locations, you can list and manage synchronized locations by clicking **File synchronization** in the **Synchronize** sub-menu. This allows you to list and remove synchronized locations that are linked to your file.\n\n\n# Publication\n\nPublishing in StackEdit makes it simple for you to publish online your files. Once you're happy with a file, you can publish it to different hosting platforms like **Blogger**, **Dropbox**, **Gist**, **GitHub**, **Google Drive**, **WordPress** and **Zendesk**. With [Handlebars templates](http://handlebarsjs.com/), you have full control over what you export.\n\n> Before starting to publish, you must link an account in the **Publish** sub-menu.\n\n## Publish a File\n\nYou can publish your file by opening the **Publish** sub-menu and by clicking **Publish to**. For some locations, you can choose between the following formats:\n\n- Markdown: publish the Markdown text on a website that can interpret it (**GitHub** for instance),\n- HTML: publish the file converted to HTML via a Handlebars template (on a blog for example).\n\n## Update a publication\n\nAfter publishing, StackEdit keeps your file linked to that publication which makes it easy for you to re-publish it. Once you have modified your file and you want to update your publication, click on the **Publish now** button in the navigation bar.\n\n> **Note:** The **Publish now** button is disabled if your file has not been published yet.\n\n## Manage file publication\n\nSince one file can be published to multiple locations, you can list and manage publish locations by clicking **File publication** in the **Publish** sub-menu. This allows you to list and remove publication locations that are linked to your file.\n\n\n# Markdown extensions\n\nStackEdit extends the standard Markdown syntax by adding extra **Markdown extensions**, providing you with some nice features.\n\n> **ProTip:** You can disable any **Markdown extension** in the **File properties** dialog.\n\n\n## SmartyPants\n\nSmartyPants converts ASCII punctuation characters into \"smart\" typographic punctuation HTML entities. For example:\n\n|                |ASCII                          |HTML                         |\n|----------------|-------------------------------|-----------------------------|\n|Single backticks|`'Isn't this fun?'`            |'Isn't this fun?'            |\n|Quotes          |`\"Isn't this fun?\"`            |\"Isn't this fun?\"            |\n|Dashes          |`-- is en-dash, --- is em-dash`|-- is en-dash, --- is em-dash|\n\n\n## KaTeX\n\nYou can render LaTeX mathematical expressions using [KaTeX](https://khan.github.io/KaTeX/):\n\nThe *Gamma function* satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral\n\n$$\n\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.\n$$\n\n> You can find more information about **LaTeX** mathematical expressions [here](http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference).\n\n\n## UML diagrams\n\nYou can render UML diagrams using [Mermaid](https://mermaidjs.github.io/). For example, this will produce a sequence diagram:\n\n```mermaid\nsequenceDiagram\nAlice ->> Bob: Hello Bob, how are you?\nBob-->>John: How about you John?\nBob--x Alice: I am good thanks!\nBob-x John: I am good thanks!\nNote right of John: Bob thinks a long<br/>long time, so long<br/>that the text does<br/>not fit on a row.\n\nBob-->Alice: Checking with John...\nAlice->John: Yes... John, how are you?\n```\n\nAnd this will produce a flow chart:\n\n```mermaid\ngraph LR\nA[Square Rect] -- Link text --> B((Circle))\nA --> C(Round Rect)\nB --> D{Rhombus}\nC --> D\n```\n","properties":"\n","discussions":{},"comments":{},"hash":-131821423}},"syncHistory":{"main":[-131821423,null,-131821423]},"v":1,"hash":1606476303311,"tx":40},"ngEhJlO2HTEBESzH/content":{"id":"ngEhJlO2HTEBESzH/content","type":"content","text":"# TensorFlow.js: \n\n## *una biblioteca para Aprendizaje Automático en JavaScript*\n\nEl mundo de las herramienta o software para el diseño, ejecución, y entrenamiendo de modelos de Machine Learning se ha ido expandiendo para hacer llegar este conocimiento a más personas, con la intención además de mejorar las formas de exposición del contenido y disminuir los tiempo de implementación. \nEs así como nace **TensorFlow.js**, a manos de Nihil Thorat y\nDaniel Smilkov, con la intención de aprovechar las herramientas de visualización y ubicuidad que tienen los navegadores web, así como la necesidad de incluir en el mundo del Machine Learning a una de las mayores comunidades de programadores y desarrolladores. \nEsta nueva API a pesar de tener mucho menos tiempo que su hermana mayor en C/C++ para Python, posee una amplia funcionalidad y compatibilidad con esta, además de un desarrollo y soporte que la tienen hoy en día en su versión 2.0.\n\n\n","properties":"\n","discussions":{},"comments":{},"hash":1223881783,"tx":45},"ngEhJlO2HTEBESzH/syncedContent":{"id":"ngEhJlO2HTEBESzH/syncedContent","type":"syncedContent","historyData":{"1223881783":{"id":"ngEhJlO2HTEBESzH/content","type":"content","text":"# TensorFlow.js: \n\n## *una biblioteca para Aprendizaje Automático en JavaScript*\n\nEl mundo de las herramienta o software para el diseño, ejecución, y entrenamiendo de modelos de Machine Learning se ha ido expandiendo para hacer llegar este conocimiento a más personas, con la intención además de mejorar las formas de exposición del contenido y disminuir los tiempo de implementación. \nEs así como nace **TensorFlow.js**, a manos de Nihil Thorat y\nDaniel Smilkov, con la intención de aprovechar las herramientas de visualización y ubicuidad que tienen los navegadores web, así como la necesidad de incluir en el mundo del Machine Learning a una de las mayores comunidades de programadores y desarrolladores. \nEsta nueva API a pesar de tener mucho menos tiempo que su hermana mayor en C/C++ para Python, posee una amplia funcionalidad y compatibilidad con esta, además de un desarrollo y soporte que la tienen hoy en día en su versión 2.0.\n\n\n","properties":"\n","discussions":{},"comments":{},"hash":1223881783}},"syncHistory":{"main":[1223881783,null,null]},"v":1,"hash":1606476306284,"tx":45},"3Onhrwns2UKPGrmE/contentState":{"id":"3Onhrwns2UKPGrmE/contentState","type":"contentState","selectionStart":326,"selectionEnd":326,"scrollPosition":{"sectionIdx":5,"posInSection":0.5425531914893617},"hash":1606476308771,"tx":49},"Nxop4XKtLamIHaeN/content":{"id":"Nxop4XKtLamIHaeN/content","type":"content","text":"# Aprendizaje Profundo\n### *Redes Neuronales mediante TensorFlow.js*\n\nEl Deep Learning o Aprendizaje Profundo, es un subcampo del Machine Learning que utiliza como arquitectura fundamental las *Redes Neuronales*.\nEn esta sección, se introduce este campo de la Inteligencia Artificial, haciendo un breve introducción sobre el ámbito del Aprendizaje Automático y .\n\n- Inteligencia Artificial, Aprendizaje Automático y Aprendizaje Profundo.\n- Breve historia de la IA y el Aprendizaje Profundo.\nasdasdkabsdas\n\n## Redes Neuronales\n- Introducción a las Redes Neuronales.\n- Primeros modelos en TensorFlow.js\n\n## Redes Convolucionales\n- Introducción a las Redes Neuronales Convolucionales\n- Modelos de Redes Neuronales Convolucionales en TensorFlow.js\n\n## Modelos Generativos\n- Introducción a las Redes Generativas Adversarias, GAN.\n- Modelos de Redes Generativas Adversarias en TensorFlow.js\n\n","properties":"\n","discussions":{},"comments":{},"hash":-601981126,"tx":53},"Nxop4XKtLamIHaeN/syncedContent":{"id":"Nxop4XKtLamIHaeN/syncedContent","type":"syncedContent","historyData":{"-601981126":{"id":"Nxop4XKtLamIHaeN/content","type":"content","text":"# Aprendizaje Profundo\n### *Redes Neuronales mediante TensorFlow.js*\n\nEl Deep Learning o Aprendizaje Profundo, es un subcampo del Machine Learning que utiliza como arquitectura fundamental las *Redes Neuronales*.\nEn esta sección, se introduce este campo de la Inteligencia Artificial, haciendo un breve introducción sobre el ámbito del Aprendizaje Automático y .\n\n- Inteligencia Artificial, Aprendizaje Automático y Aprendizaje Profundo.\n- Breve historia de la IA y el Aprendizaje Profundo.\nasdasdkabsdas\n\n## Redes Neuronales\n- Introducción a las Redes Neuronales.\n- Primeros modelos en TensorFlow.js\n\n## Redes Convolucionales\n- Introducción a las Redes Neuronales Convolucionales\n- Modelos de Redes Neuronales Convolucionales en TensorFlow.js\n\n## Modelos Generativos\n- Introducción a las Redes Generativas Adversarias, GAN.\n- Modelos de Redes Generativas Adversarias en TensorFlow.js\n\n","properties":"\n","discussions":{},"comments":{},"hash":-601981126}},"syncHistory":{"main":[-601981126,-601981126,null]},"v":1,"hash":1606481423832,"tx":61},"t8aD6kgGQvq7Q4qZ/content":{"id":"t8aD6kgGQvq7Q4qZ/content","type":"content","text":"# La Inteligencia Artificial y el Aprendizaje Automático\n\nLa Inteligencia Artificial o IA, es un campo de investigación y estudio que intenta comprender *cómo los seres humanos pensamos* y construir a partir de esto entidades o máquinas que muestren capacidades cognitivas, que perciban, entiendan, infieran o deduzcan, es decir, que demuestren *inteligencia*.\n\nEl Aprendizaje Automático o Machine Learning, es un subcampo de la Inteligencia Artificial, que intenta dotar a una máquina o sistema con la capacidad de aprender de datos sin haber sido explícitamente programada. Para esto se desarrollan técnicas con la capacidad de generalizar comportamientos y aprender patrones, y de esta forma mejorar, describir y predecir ciertos resultados.\n\nEn general, las técnicas o enfoques del Aprendizaje Automático se pueden dividir en 3 categorías:\n - **Aprendizaje Supervisado:** al sistema o máquina se le presenta un conjunto de datos o ejemplos de entrenamiento, compuestos por los valores de entrada y los valores de salida deseados. A partir de ello se busca generalizar un patrón mediante algún algoritmo para hacer predicciones de datos no conocidos fuera del conjunto de datos de entrenamiento.\n - **Aprendizaje No Supervisado:** el sistema se dota de un conjunto de entrenamiento compuesto sólo por los valores de entrada, sin los valores de salida deseados. Es decir, el conjunto de entrenamiento no contiene los resultados debidamente etiquetados, clasificados o categorizados para cada uno de los valores de entrada, por lo que el algorítmo debe aprender a realizar la clasificación o categorización de los datos sólo a partir de los valores de entrada.\n- **Aprendizaje por Refuerzo:** el sistema o máquina a través de la interacción aprende lo bueno o malo de una acción a través del resultado obtenido. Si la acción o comportamiento es el correcto, por ejemplo, la recompensa puede ser positiva, en caso contrario, la recompensa será negativa.\n\n# El Aprendizaje Profundo\nEl Deep Learning o Aprendizaje Profundo, es un subcampo del Machine Learning que utiliza como arquitectura fundamental *Redes Neuronales*. Utiliza este tipo de redes como forma para extraer información de los datos con el menor esfuerzo humano posible, intentando realizar este proceso de forma automática.\n\nGran parte de los conceptos básicos del *Aprendizaje Profundo* surgieron en los años 60, 80 y 90, pero ha tenido su mayor auge en la última década debido principalmente a factores tales como: \n- Digitalización de la información y la consiguiente habilidad de acceder a datos fácilmente, haciendo que muchos problemas tengan ahora una forma digital. \n- Grandes avances de las telecomunicaciones y en especial el internet, que le permiten a las comunidades científicas la capacidad de trabajar y compartir remotamente. \n- Grandes avances en la computación y el diseño de nuevo hardware (CPU, GPU, TPU), permitiendo la ejecución efectiva a gran escala. \n- Desarrollo de herramientas como TensorFlow, PyTorch y Keras con grandes niveles de abstracción que ayudan a las personas a resolver problemas en cada vez menos tiempo y con cada vez menos conocimientos, dejando a la *idea* y los *datos* como el punto central.\n\nPara esto, utiliza un conjunto de datos de ejemplo como **base o set de entrenamiento** que se utiliza para reconocer patrones. Una vez que se extraen estos patrones, el sistema puede ser capáz de utilizarlos para *etiquetar* nuevos datos de entrada.\nLas Redes Neuronales son un modelo basado en el funcionamiento del cerebro, diseñado para el reconocimiento de patrones. Estos patrones son numéricos y están contenidos en vectores, como representación de los datos recibidos como entrada.\n\n## Estructura de las Redes Neuronales\nLas redes neuronales están compuestas por capas, y cada una de estas capas está compuesta por nodos o neuronas. Los nodos tienen la siguiente estructura:\n- Una o más entradas que reciben los datos a procesar.\n- Pesos dados a cada una de las entradas. Estos aumentan o disminuyen la importancia de dicha entrada.\n- Función sumatoria, encargada de sumar todas las combinaciones de peso-entrada.\n- Función de activación, que determina la activación o no de un nodo según el valor obtenido en la función sumatoria. Esta función puede ser una simple función escalón, una función lineal que devuelve el mismo valor calculado o una función lineal por tramos, como la función ReLU, que devuelve un valor si el valor de la función sumatoria está dentro de ciertos límites, entre otras.\n\nPara entender el modelo de redes neuronales, se deben definir los siguientes concepto básicos:\n- **Etiquetas:** tambień llamadas *labels* por su nombre en inglés. Corresponde al valor, clasificación o categoría a predecir.\n- **Atributos:** también llamados *features*. Corresponden a las variables de entrada a cada nodo o neurona.\n- **Set de datos:** corresponde a los ejemplos a utilizar para entrenar o hacer predicciones con el modelo. \nEstos ejemplos pueden corresponder a atributos debidamente etiquetados, que suelen utilizarse como ejemplos de entrenamiento para un modelo, o pueden corresponder a atributos sin etiquetar que se utilizan para probar el modelo ya entrenado o en instancias de aprendizaje no supervisado.\n\n## Entrenamiento de una red neuronal\nCon el fin de extraer información de los datos, el modelo de red neuronal debe definir la relación entre las entradas o atributos y su salida o etiquetas. Para esto el modelo debe pasar por el proceso de entrenamiento o aprendizaje para posteriormente poder hacer inferencias de acuerdo a los patrones aprendidos durante el entrenamiento.\nEn el **proceso de entrenamiento** ocurre un ajuste o modificación de los pesos asociados a cada entrada a un nodo, con el fin de minimizar una **función de pérdida**. Esta **función de pérdida** recibe la predicción **ŷ** y la etiqueta correcta **y**, asociadas a cierto atributo. Con esto, la *Función de Pérdida* calcula lo incorrecto o no de una predicción. \nEstas *Funciones de Pérdida o Costo* pueden eleguirse de acuerdo al tipo de modelo de red neuronal a implementar para evaluar su rendimiento o performance. Entre estas, una de las más utilizadas es la MSE, Mean Square Error, también conocida como *Costo cuadrático medio*, definida como:\n\n$$MSE = \\frac{1}{N} \\sum (y - (prediccion(x)))^2$$\n  \nLos pesos se suelen inicializar con valores escogidos de forma aleatoria, y generalmente son números pequeños. El ajuste de estos pesos ocurre gracias a un algoritmo de optimización, que ayudan a reducir o minimizar la *Función de Pérdida*. Estos algoritmos de optimización suelen estar basados en el cálculo del **gradiente** de la *función de pérdida*, debido a que éste indica la dirección de máximo crecimiento de la función en cierto punto. Este tipo de algoritmos es por tanto llamado **Descenso de Gradiente**, y son técnicas conocidas como **Gradient Descent Optimization**. Entre ellas se encuentran una gran variedad de algoritmos que implementan el Descenso de Gradiente, tales como Adagrad, Adadelta, Adam, Adamax y Nadam.\nPara actualizar el peso una vez que la *Función de Pérdida* a calculado el error y el algoritmo de optimización a recalculado los pesos para *minimizar la Función de Pérdida*, se recurre a un algoritmo de propagación hacia atrás, desde la capa de salida hacia las capas anteriores. Este algoritmo de propagación se conoce como **Backpropagation** o **Propagación hacia atras**.\n\n","properties":"\n","discussions":{},"comments":{},"hash":-601391086,"tx":1622},"t8aD6kgGQvq7Q4qZ/contentState":{"id":"t8aD6kgGQvq7Q4qZ/contentState","type":"contentState","selectionStart":6287,"selectionEnd":6287,"scrollPosition":{"sectionIdx":0,"posInSection":0},"hash":1606543274111,"tx":1633},"t8aD6kgGQvq7Q4qZ/syncedContent":{"id":"t8aD6kgGQvq7Q4qZ/syncedContent","type":"syncedContent","historyData":{"-601391086":{"id":"t8aD6kgGQvq7Q4qZ/content","type":"content","text":"# La Inteligencia Artificial y el Aprendizaje Automático\n\nLa Inteligencia Artificial o IA, es un campo de investigación y estudio que intenta comprender *cómo los seres humanos pensamos* y construir a partir de esto entidades o máquinas que muestren capacidades cognitivas, que perciban, entiendan, infieran o deduzcan, es decir, que demuestren *inteligencia*.\n\nEl Aprendizaje Automático o Machine Learning, es un subcampo de la Inteligencia Artificial, que intenta dotar a una máquina o sistema con la capacidad de aprender de datos sin haber sido explícitamente programada. Para esto se desarrollan técnicas con la capacidad de generalizar comportamientos y aprender patrones, y de esta forma mejorar, describir y predecir ciertos resultados.\n\nEn general, las técnicas o enfoques del Aprendizaje Automático se pueden dividir en 3 categorías:\n - **Aprendizaje Supervisado:** al sistema o máquina se le presenta un conjunto de datos o ejemplos de entrenamiento, compuestos por los valores de entrada y los valores de salida deseados. A partir de ello se busca generalizar un patrón mediante algún algoritmo para hacer predicciones de datos no conocidos fuera del conjunto de datos de entrenamiento.\n - **Aprendizaje No Supervisado:** el sistema se dota de un conjunto de entrenamiento compuesto sólo por los valores de entrada, sin los valores de salida deseados. Es decir, el conjunto de entrenamiento no contiene los resultados debidamente etiquetados, clasificados o categorizados para cada uno de los valores de entrada, por lo que el algorítmo debe aprender a realizar la clasificación o categorización de los datos sólo a partir de los valores de entrada.\n- **Aprendizaje por Refuerzo:** el sistema o máquina a través de la interacción aprende lo bueno o malo de una acción a través del resultado obtenido. Si la acción o comportamiento es el correcto, por ejemplo, la recompensa puede ser positiva, en caso contrario, la recompensa será negativa.\n\n# El Aprendizaje Profundo\nEl Deep Learning o Aprendizaje Profundo, es un subcampo del Machine Learning que utiliza como arquitectura fundamental *Redes Neuronales*. Utiliza este tipo de redes como forma para extraer información de los datos con el menor esfuerzo humano posible, intentando realizar este proceso de forma automática.\n\nGran parte de los conceptos básicos del *Aprendizaje Profundo* surgieron en los años 60, 80 y 90, pero ha tenido su mayor auge en la última década debido principalmente a factores tales como: \n- Digitalización de la información y la consiguiente habilidad de acceder a datos fácilmente, haciendo que muchos problemas tengan ahora una forma digital. \n- Grandes avances de las telecomunicaciones y en especial el internet, que le permiten a las comunidades científicas la capacidad de trabajar y compartir remotamente. \n- Grandes avances en la computación y el diseño de nuevo hardware (CPU, GPU, TPU), permitiendo la ejecución efectiva a gran escala. \n- Desarrollo de herramientas como TensorFlow, PyTorch y Keras con grandes niveles de abstracción que ayudan a las personas a resolver problemas en cada vez menos tiempo y con cada vez menos conocimientos, dejando a la *idea* y los *datos* como el punto central.\n\nPara esto, utiliza un conjunto de datos de ejemplo como **base o set de entrenamiento** que se utiliza para reconocer patrones. Una vez que se extraen estos patrones, el sistema puede ser capáz de utilizarlos para *etiquetar* nuevos datos de entrada.\nLas Redes Neuronales son un modelo basado en el funcionamiento del cerebro, diseñado para el reconocimiento de patrones. Estos patrones son numéricos y están contenidos en vectores, como representación de los datos recibidos como entrada.\n\n## Estructura de las Redes Neuronales\nLas redes neuronales están compuestas por capas, y cada una de estas capas está compuesta por nodos o neuronas. Los nodos tienen la siguiente estructura:\n- Una o más entradas que reciben los datos a procesar.\n- Pesos dados a cada una de las entradas. Estos aumentan o disminuyen la importancia de dicha entrada.\n- Función sumatoria, encargada de sumar todas las combinaciones de peso-entrada.\n- Función de activación, que determina la activación o no de un nodo según el valor obtenido en la función sumatoria. Esta función puede ser una simple función escalón, una función lineal que devuelve el mismo valor calculado o una función lineal por tramos, como la función ReLU, que devuelve un valor si el valor de la función sumatoria está dentro de ciertos límites, entre otras.\n\nPara entender el modelo de redes neuronales, se deben definir los siguientes concepto básicos:\n- **Etiquetas:** tambień llamadas *labels* por su nombre en inglés. Corresponde al valor, clasificación o categoría a predecir.\n- **Atributos:** también llamados *features*. Corresponden a las variables de entrada a cada nodo o neurona.\n- **Set de datos:** corresponde a los ejemplos a utilizar para entrenar o hacer predicciones con el modelo. \nEstos ejemplos pueden corresponder a atributos debidamente etiquetados, que suelen utilizarse como ejemplos de entrenamiento para un modelo, o pueden corresponder a atributos sin etiquetar que se utilizan para probar el modelo ya entrenado o en instancias de aprendizaje no supervisado.\n\n## Entrenamiento de una red neuronal\nCon el fin de extraer información de los datos, el modelo de red neuronal debe definir la relación entre las entradas o atributos y su salida o etiquetas. Para esto el modelo debe pasar por el proceso de entrenamiento o aprendizaje para posteriormente poder hacer inferencias de acuerdo a los patrones aprendidos durante el entrenamiento.\nEn el **proceso de entrenamiento** ocurre un ajuste o modificación de los pesos asociados a cada entrada a un nodo, con el fin de minimizar una **función de pérdida**. Esta **función de pérdida** recibe la predicción **ŷ** y la etiqueta correcta **y**, asociadas a cierto atributo. Con esto, la *Función de Pérdida* calcula lo incorrecto o no de una predicción. \nEstas *Funciones de Pérdida o Costo* pueden eleguirse de acuerdo al tipo de modelo de red neuronal a implementar para evaluar su rendimiento o performance. Entre estas, una de las más utilizadas es la MSE, Mean Square Error, también conocida como *Costo cuadrático medio*, definida como:\n\n$$MSE = \\frac{1}{N} \\sum (y - (prediccion(x)))^2$$\n  \nLos pesos se suelen inicializar con valores escogidos de forma aleatoria, y generalmente son números pequeños. El ajuste de estos pesos ocurre gracias a un algoritmo de optimización, que ayudan a reducir o minimizar la *Función de Pérdida*. Estos algoritmos de optimización suelen estar basados en el cálculo del **gradiente** de la *función de pérdida*, debido a que éste indica la dirección de máximo crecimiento de la función en cierto punto. Este tipo de algoritmos es por tanto llamado **Descenso de Gradiente**, y son técnicas conocidas como **Gradient Descent Optimization**. Entre ellas se encuentran una gran variedad de algoritmos que implementan el Descenso de Gradiente, tales como Adagrad, Adadelta, Adam, Adamax y Nadam.\nPara actualizar el peso una vez que la *Función de Pérdida* a calculado el error y el algoritmo de optimización a recalculado los pesos para *minimizar la Función de Pérdida*, se recurre a un algoritmo de propagación hacia atrás, desde la capa de salida hacia las capas anteriores. Este algoritmo de propagación se conoce como **Backpropagation** o **Propagación hacia atras**.\n\n","properties":"\n","discussions":{},"comments":{},"hash":-601391086}},"syncHistory":{"main":[-601391086,-601391086,null]},"v":1,"hash":1606543279791,"tx":1634},"8qtJa4OoGIQAnMPI":{"id":"8qtJa4OoGIQAnMPI","type":"folder","name":"intro","parentId":null,"hash":615584379,"tx":1635},"t8aD6kgGQvq7Q4qZ":{"id":"t8aD6kgGQvq7Q4qZ","type":"file","name":"IA, ML y DL","parentId":"8qtJa4OoGIQAnMPI","hash":1691181492,"tx":1636},"sE8uhT86oltmXjsx":{"id":"sE8uhT86oltmXjsx","type":"file","name":"Breve historia IA","parentId":"8qtJa4OoGIQAnMPI","hash":1285508111,"tx":1637},"dataSyncData":{"id":"dataSyncData","type":"data","data":{"badgeCreations":{"id":"1HKg5j2RyL6h2gYmEuXbyN2N38g8raGIo9PGOYPONxVbFgoLBoQ","itemId":"badgeCreations","type":"data","hash":-278927930},"templates":{"id":"1PNi3fjQInymDYA8INCfo2Jqmiih0BRCmapoQCsmGaXgEvULjOQ","itemId":"templates","type":"data","hash":-972705388}},"hash":2013830319,"tx":1640},"sE8uhT86oltmXjsx/content":{"id":"sE8uhT86oltmXjsx/content","type":"content","text":"### Breve historia de la IA y el Aprendizaje Profundo\n\nLa Inteligencia Artificial, y más específicamente el Aprendizaje Profundo, está basado en ideas de los años 60, 80 y 90. A pesar de que se puede pensar que son descubrimientos recientes, es un campo que ha tenido una lenta y gradual evolución a través de varias décadas. A continuación se presenta un resumen no exhaustivo de parte de los grandes hitos en su desarrollo:\n\n- **1943:** Warren S. McCulloch y Walter Pitts llevan el modelo conocido de la neuronas a la matemática, mostrando con esto el primero modelo matemático de la neurona biológica.\n- **1957:** Frank F. Rosenblatt basandose en el modelo matemático propuesto por Pitts y McCulloch, propone la idea del *Perceptron*, una red neuronal de una sola capa capaz de realizar clasificación binaria. Un par de años más tarde (1962) propone también la idea de una red de múltiples capas.\n- **1960:** Henry J. Kelley muestra por primera vez un modelo de propagación hacia atrás o Backpropagation en el contexto de la Teoría de Control.\n- **1962:** Stuart Dreyfus demuestra un modelo de Backpropagation que funciona utilizando simples derivadas y la regla de la cadena.\n- **1965:** Alexey Grigoryevich Ivakhnenko y Valentin Grigorevich Lapa crean el primer algorítmo de aprendizaje para el entrenamiento de perceptrones multicapa, utilizando entrenamiento GMDH (Group Method of Data Handling o Método de agrupamiento para el manejo de datos) y funciones de activación polinomial. Son considerador por esto como los padres del *Deep Learning*.\n- **1970:** Seppo Linnainmaa presenta en su tesis de Master y en un  artículo posterior el primer código de diferenciación automática y Backpropagation.\n- **1980:** Kunihiko Fukushima inventa las Convolutional Neural Network (CNN) al proponer su arquitectura *Neocognitron* capaz de reconocer patrones visuales.\n- **1982:** John Hopfield crea la primera arquitectura reconocida como una Recurrent Neural Network (RNN). Esta misma sería conocida más tarde como *Hopfield Network*, siendo fundamental para los modelos posteriores de RNN.\n- **1985:** David H.Ackley, Geoffrey E.Hinton y Terrence J.Sejnowski crean la Boltzmann Machine, una especie de RNN estocástica sin capa de salida.\n- **1986:** David E. Rumelhart, Geoffrey E. Hinton y Ronald J. Williams muestran la primera implementación exitosa del algorítmo de Backpropagation en el entrenamiento de las redes neuronales.\n- **1989:** Yann LeCun muestra la primera implementación del algorítmo de Backpropagation en el entrenamiento de Convolutional Neural Network.\n- **1997:** Sepp Hochreiter and Jürgen Schmidhuber proponen la arquitectura Long Short-Term Memory (LSTM), una arquitectura de red tipo RNN con conexiones del tipo *feedback* que le permiten procesar secuencias de datos.\n- **2006:** Geoffrey E. Hinton, Simon Osindero y Yee Whye Teh crean la Deep Belief Network y mejoran el proceso de entrenamiento haciendolo más eficiente. Se comienza a utilizar el término *Deep Learning* con la connotación que hoy se conoce.\n- **2009:** Fei-Fei Li lanza ImageNet. Base de datos de más de 14 millones de imágenes y más de 20000 categorías debidamente etiquetadas.\n- **2012:** Alex Krizhevsky presenta AlexNet en NIPS, un modelo o arquitectura que implementa Convolutional Neural Networks mediante GPU, alcanzando una capacidad en la clasificación de imágenes de ImageNet del estado del arte.\n- **2014:** Ian Goodfellow propone las Generative Adversarial Network, conocidas como GAN. Con ello se abre la puerta a la aplicación de generación de imagénes y video debido a su gran capacidad de sintetizar datos.\n\n \nPara un cuadro más exhaustivo de la historia de la IA y el Deep Learning, se sugiere revisar el árticulo \"Deep Learning in Neural Networks: An Overview\" por Juergen Schmidhuber, en el que intenta hacer una recopilación de cada una las personas que han contribuido al desarrollo del Deep Learning.\n","properties":"\n","discussions":{},"comments":{},"hash":637348124,"tx":2096},"sE8uhT86oltmXjsx/contentState":{"id":"sE8uhT86oltmXjsx/contentState","type":"contentState","selectionStart":3686,"selectionEnd":3686,"scrollPosition":{"sectionIdx":0,"posInSection":0},"hash":1606545335509,"tx":2101},"sE8uhT86oltmXjsx/syncedContent":{"id":"sE8uhT86oltmXjsx/syncedContent","type":"syncedContent","historyData":{"637348124":{"id":"sE8uhT86oltmXjsx/content","type":"content","text":"### Breve historia de la IA y el Aprendizaje Profundo\n\nLa Inteligencia Artificial, y más específicamente el Aprendizaje Profundo, está basado en ideas de los años 60, 80 y 90. A pesar de que se puede pensar que son descubrimientos recientes, es un campo que ha tenido una lenta y gradual evolución a través de varias décadas. A continuación se presenta un resumen no exhaustivo de parte de los grandes hitos en su desarrollo:\n\n- **1943:** Warren S. McCulloch y Walter Pitts llevan el modelo conocido de la neuronas a la matemática, mostrando con esto el primero modelo matemático de la neurona biológica.\n- **1957:** Frank F. Rosenblatt basandose en el modelo matemático propuesto por Pitts y McCulloch, propone la idea del *Perceptron*, una red neuronal de una sola capa capaz de realizar clasificación binaria. Un par de años más tarde (1962) propone también la idea de una red de múltiples capas.\n- **1960:** Henry J. Kelley muestra por primera vez un modelo de propagación hacia atrás o Backpropagation en el contexto de la Teoría de Control.\n- **1962:** Stuart Dreyfus demuestra un modelo de Backpropagation que funciona utilizando simples derivadas y la regla de la cadena.\n- **1965:** Alexey Grigoryevich Ivakhnenko y Valentin Grigorevich Lapa crean el primer algorítmo de aprendizaje para el entrenamiento de perceptrones multicapa, utilizando entrenamiento GMDH (Group Method of Data Handling o Método de agrupamiento para el manejo de datos) y funciones de activación polinomial. Son considerador por esto como los padres del *Deep Learning*.\n- **1970:** Seppo Linnainmaa presenta en su tesis de Master y en un  artículo posterior el primer código de diferenciación automática y Backpropagation.\n- **1980:** Kunihiko Fukushima inventa las Convolutional Neural Network (CNN) al proponer su arquitectura *Neocognitron* capaz de reconocer patrones visuales.\n- **1982:** John Hopfield crea la primera arquitectura reconocida como una Recurrent Neural Network (RNN). Esta misma sería conocida más tarde como *Hopfield Network*, siendo fundamental para los modelos posteriores de RNN.\n- **1985:** David H.Ackley, Geoffrey E.Hinton y Terrence J.Sejnowski crean la Boltzmann Machine, una especie de RNN estocástica sin capa de salida.\n- **1986:** David E. Rumelhart, Geoffrey E. Hinton y Ronald J. Williams muestran la primera implementación exitosa del algorítmo de Backpropagation en el entrenamiento de las redes neuronales.\n- **1989:** Yann LeCun muestra la primera implementación del algorítmo de Backpropagation en el entrenamiento de Convolutional Neural Network.\n- **1997:** Sepp Hochreiter and Jürgen Schmidhuber proponen la arquitectura Long Short-Term Memory (LSTM), una arquitectura de red tipo RNN con conexiones del tipo *feedback* que le permiten procesar secuencias de datos.\n- **2006:** Geoffrey E. Hinton, Simon Osindero y Yee Whye Teh crean la Deep Belief Network y mejoran el proceso de entrenamiento haciendolo más eficiente. Se comienza a utilizar el término *Deep Learning* con la connotación que hoy se conoce.\n- **2009:** Fei-Fei Li lanza ImageNet. Base de datos de más de 14 millones de imágenes y más de 20000 categorías debidamente etiquetadas.\n- **2012:** Alex Krizhevsky presenta AlexNet en NIPS, un modelo o arquitectura que implementa Convolutional Neural Networks mediante GPU, alcanzando una capacidad en la clasificación de imágenes de ImageNet del estado del arte.\n- **2014:** Ian Goodfellow propone las Generative Adversarial Network, conocidas como GAN. Con ello se abre la puerta a la aplicación de generación de imagénes y video debido a su gran capacidad de sintetizar datos.\n\n \nPara un cuadro más exhaustivo de la historia de la IA y el Deep Learning, se sugiere revisar el árticulo \"Deep Learning in Neural Networks: An Overview\" por Juergen Schmidhuber, en el que intenta hacer una recopilación de cada una las personas que han contribuido al desarrollo del Deep Learning.\n","properties":"\n","discussions":{},"comments":{},"hash":637348124}},"syncHistory":{"main":[637348124,637348124,null]},"v":1,"hash":1606545338930,"tx":2103},"Nxop4XKtLamIHaeN/contentState":{"id":"Nxop4XKtLamIHaeN/contentState","type":"contentState","selectionStart":0,"selectionEnd":0,"scrollPosition":{"sectionIdx":0,"posInSection":0},"hash":1606545381242,"tx":2105},"ngEhJlO2HTEBESzH/contentState":{"id":"ngEhJlO2HTEBESzH/contentState","type":"contentState","selectionStart":0,"selectionEnd":0,"scrollPosition":{"sectionIdx":0,"posInSection":0},"hash":1606545383157,"tx":2106},"2uMtKUmHDISxs6dy/content":{"id":"2uMtKUmHDISxs6dy/content","type":"content","text":"# Una introducción a las Redes Generativas Adversarias\n\n  \n\n## GANs: Generative Adversarial Networks\n\n  \n\nLas Redes Generativas Adversariales, o GANs, fueron descritas por primera vez el 2014 en el artículo de Ian Goodfellow, \"Generative Adversarial Networks\". Son una clase dentro de las técnicas del Machine Learning que permiten la generación de imagénes sintéticas, forzando las imágenes sintéticas generadas a ser estadísticamente indistinguibles de las imágenes originales. La gran capacidad de generación y la potencia de la idea de las redes adversariales generativas ha hecho que en los últimos años se haya puesto el foco en su investigación y en la generación de nuevas arquitecturas.\n\nLas GANs consisten básicamente en dos redes que compiten mutuamente: una **red genera datos falsos**, y otra que **intenta distinguir los datos falsos de los reales**.\n\nDe esta forma, las GANs:\n- Es un modelo _generativo_ porque tiene como proposito el generar nuevos datos.\n- Son _redes_ porque fundamentalmente la arquitectura está compuesta de dos redes neuronales; **Discriminador** y **Generador**.\n- Son _adversarias o antagónicas_ debido a que el Discriminador compite con el Generador.\n\n  \n\n## Funcionamiento de las GAN\nLas GANs constan en su forma más básica de dos redes neuronales, _Generador_ y _Discriminador_. De acuerdo a lo anterior, los aspectos básicos y fundamentales de estas redes son:\n### Generador\n- Tiene como **entrada** un vector de números aleatorios, seleccionado de un espacio latente predefinido, como una función normal multivariada.\n- La **salida** es un ejemplo sintetizado falso que intenta ser estadísticamente lo más parecido a un ejemplo real.\n- El **objetivo** es generar datos falsos que sean indistinguibles de los datos reales.\n\n### Discriminador\n\n  \n\n- Tiene como **entradas**\n\n- Los datos reales, que provienen de la base de datos de entrenamiento.\n\n- Los datos falsos, sintetizados por el Discriminador.\n\n- La **salida** es la probabilidad del ejemplo de entrada de ser real.\n\n- El **objetivo** es distinguir los datos falsos provenientes del Generador y los datos reales provenientes de la base de datos.\n\n  \n\nDe esta forma, se definen:\n\n  \n\n-  **Conjunto de entrenamiento:** Base de datos de ejemplos reales. El Generador debe aprender a emular de forma\n\nperfecta estos datos. Estos datos sirven como entrada a la red Discriminador.\n\n-  **Vector de ruido aleatorio:** Vector **z** de entrada a la red Generador. Esta entrada es utilizada por el Generador como punto de partida para la síntesis de datos falsos.\n\n-  **Red Generadora:** Toma como entrada un vector de números aleatorio **z**, y genera como salida un dato\n\nfalso **x\\***. El objetivo es que el dato falso sea indistinguible del dato real.\n\n-  **Red Discriminadora:** Toma como entrada un dato real **x** o un dato falso **x\\***. El objetivo es determinar, para cada dato, la probabilidad si es real.\n\n-  **Proceso iterativo de entrenamiento/sintonización:** Para cada una de las predicciones del Discriminador,\n\nse determina lo buena o no de esta, y se utiliza el resultado para volver a sintonizar la red Discriminadora\n\ny Generadora mediante _Propagación hacia atrás_ (Backpropagation).\n  \n\n- **Conjunto de entrenamiento:** Base de datos de ejemplos reales. El Generador debe aprender a emular de forma perfecta estos datos. Estos datos sirven como entrada a la red Discriminador.\n- **Vector de ruido aleatorio:** Vector **z** de entrada a la red Generador. Esta entrada es utilizada por el Generador como punto de partida para la síntesis de datos falsos.\n- **Red Generadora:** Toma como entrada un vector de números aleatorio **z**, y genera como salida un dato falso **x\\***. El objetivo es que el dato falso sea indistinguible del dato real.\n- **Red Discriminadora:** Toma como entrada un dato real **x** o un dato falso **x\\***. El objetivo es determinar, para cada dato, la probabilidad si es real.\n- **Proceso iterativo de entrenamiento/sintonización:** Para cada una de las predicciones del Discriminador, se determina lo buena o no de esta, y se utiliza el resultado para volver a sintonizar la red Discriminadora y Generadora mediante _Propagación hacia atrás_ (Backpropagation).\n\n##  Proceso básico de entrenamiento\n\nEl algorítmo de entrenamiento para una GAN para cada uno de los ciclos de iteración es como sigue:\n- Entrenamiento del _Discriminador_:\n\t- Se toma una muestra aleatoria **x** desde el conjunto de entrenamiento.\n\t- Se obtiene un nuevo vector aleatorio **z**, y usando la red del Generador se sintetiza un ejemplo falso **x\\***.\n\t- Se usa la red del Discriminador para clasificar **x** y **x\\***.\n\t- Se calculan los errores de clasificación y se propaga hacia atras (backpropagation) el error total para actualizar los parámetros de entrenamiento del Discriminador, intentando minimizar el error de clasificación.\n- Entrenamiento del _Generador_:\n\t- Se toma un nuevo vector aleatorio **z**, y se usa la red del Generador para sintetizar un ejemplo falso **x\\***.\n\t- Se usa el Discriminador para clasificar **x**.\n\t- Se calculan los errores de clasificación y se propaga hacia atras (backpropagation) el error para actualizar los parámetros de entrenamiento del Generador, intentando maximizar el error del Discriminador.\n\n  \n\nDebido a que este proceso de entrenamiento es iterativo, cada vez que el _Discriminador_ es entrenado y mejora respecto al _Generador_, el _Generador_ es actualizado y mejora en el proceso.\nLo anterior, en palabras más simples, se debe a que el _Generador_ y el _Discriminador_ están inmersos en un _juego de suma cero_, debido a que cada red tiene como objetivo mejorar respecto a la otra, haciendo que la otra red empeore. Esto lleva a que la arquitectura deba tender a un punto de _equilibrio_, en el cual ninguna de las dos pueda seguir mejorando.\n\nDe acuerdo Ian Goodfellow, teóricamente para cada red _Generador_ existe una única red _Discriminador_ óptima. Se muestra también que el _Generador_ es óptimo cuando el _Discriminador_ alcanza predicciones de un valor de 0.5 para todas las entradas. Es decir, el _Generador_ es óptimo cuando el _Discriminador_ está completamente confundido y es incapaz de distinguir entre datos reales y datos falsos.\n\nSin embargo, alcanzar el _equilibrio_ para una GAN, significa en la práctica alcanzar el **Equilibrio de Nash** para un caso en el que no existen algorítmos, en donde las *funciones de costo* son no convexas y el espacio de parámetros es de altas dimensiones. Debido a lo anterior, la utilización de **Gradiente Descendiente** no garantiza su convergencia, y se han desarrollado diversas arquitecturas y \"trucos\" de entrenamiento heurístico para alcanzar la convergencia.\n\nPara una explicación más detallada del funcionamiento de las GANs, se recomienda el artículo de Ian Goodfellow, \"Generative Adversarial Network\", el tutorial realizado en la conferencia NIPS de 2016 por él mismo y el Workshop realizado en la misma conferencia disponible en video.\n","properties":"\n","discussions":{},"comments":{},"hash":-415451179,"tx":2228},"4nVfhBNx6GrFL2GA":{"id":"4nVfhBNx6GrFL2GA","type":"folder","name":"GAN","parentId":null,"hash":1490316995,"tx":2246},"2uMtKUmHDISxs6dy":{"id":"2uMtKUmHDISxs6dy","type":"file","name":"how gan work","parentId":"4nVfhBNx6GrFL2GA","hash":-453991916,"tx":2247},"gkhFvwx0DRFTGKjR":{"id":"gkhFvwx0DRFTGKjR","type":"file","name":"Particularidades GAN","parentId":"4nVfhBNx6GrFL2GA","hash":-628255140,"tx":2248},"gkhFvwx0DRFTGKjR/content":{"id":"gkhFvwx0DRFTGKjR/content","type":"content","text":"# Particularidades de una GAN\n\n  \n\nLa GAN está compuesta de 2 redes neuronales, un Discriminador y un\n\nGenerador. El Discriminador es un clasificador que se entrena para\n\ndeterminar la probabilidad de que cierta imagen sea falsa. Es decir,\n\nmodela la probabilidad de que cierto ejemplo sea falso, dadas ciertas\n\ncaracterísticas de entrada. Esto es, es la probabilidad de dado una\n\nimagen de entrada $X$, $Y$ sea falsa: $$\\begin{aligned}\n\nP(Y=clase | X=características)\\end{aligned}$$ Esta probabilidad es la\n\nque se envía como retroalimentación (feedback) al Generador para su\n\najuste de pesos.\\\n\nEl principal objetivo del Generador es producir ejemplos realistas de\n\nciertas clases. Es decir, intenta encontrar y modelar el espacio de las\n\nposibilidades de ciertas clases. Esto es, dado ciertas clases $Y$ (como\n\npor ejemplo, perro y/o gatos), se quiere obtener la probabilidad de\n\nciertas características $X$. $$\\begin{aligned}\n\nP(X= características | Y= clase )\\end{aligned}$$ Si el generador\n\nsolo se entrena para producir características relevantes de sólo una\n\nclase, entonces el Generador intenta modelar la probabilidad de ciertas\n\ncaracterísticas $X$, $P(X)$\\\n\nSi la clase $Y$ son por ejemplo perros, $P(X)$ intenta modelar y\n\naproximar la distribución real de probabilidad de características de\n\ntodos los posibles perros existentes.\n\n  \n\n#### Noise Vector, vector aleatorio z\n\n  \n\nIdealmente el Generador no produce el mismo ejemplo cada vez. para lo\n\nanterior se le da un set distinto de valores aleatorios, conocidos como\n\n\"noise vector\", o \"vector ruido\". Usualmente se generan de forma\n\naleatoria, tomando valores de forma uniforme entre 0 y 1 desde una\n\ndistribución normal. $$\\begin{aligned}\n\nZ \\sim N(0,1)\\end{aligned}$$\n\n  \n\nDebe de ser lo suficientemente grande para tener la mayor cantidad de\n\nposibilidades. Generalmente se toman vectores con dimensiones en base a\n\npotencias de 2.\\\n\nLa elección y/o generación del vector Z es una parte importante del\n\nGenerador, pues puede verse como una medida del balance entre la\n\nfidelidad y calidad de la generación, y la diversidad de esta.\n\n  \n\n- Si la muestra de Z se saca de una Distribución Normal, el modelo\n\nGenerador tiene más probabilidades de ver valores de Z dentro de\n\nmedia desviación estandar.\n\n  \n\n- Con lo anterior, durante el entrenamiento del Generador, el modelo\n\ntiende a familiarizarse más con ciertos *vectores de ruido\n\naleatorio*, modelando y generando areas que salen desde estos\n\nvectores más familiares y probables.\n\n  \n\n- En estas áreas, el modelo tenderá a tener resultados posiblemente\n\nmucho más realistas, pero tenderá a no generar nada fuera de lo\n\ncomún.\n\n  \n\nLo anterior, constituye por lo tanto un **balance entre fidelidad y\n\ndiversidad**, esto es, imágenes realistas y con gran calidad, versus\n\ndiversidad y variedad de imágenes.\n\n  \n\n#### Función de pérdida\n\n  \n\nLa función de pérdida u objetivo para una GAN definida en el paper\n\noriginal [@goodfellowGenerativeAdversarialNetworks2014] está dada como:\n\n$$\\begin{aligned}\n\nJ(\\theta) = \\dfrac{-1}{m} \\sum_{i=1}^{m} \\left[\n\ny^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\} +\n\n\\left( 1-y^{i} \\right) log \\left( 1 - \\left\\{ h(x^{i}, \\theta) \\right\\} \\right)\n\n\\right]\n\n\\label{eq:cost_function}\n\n\\end{aligned}$$\n\n  \n\nEn donde:\n\n  \n\n-  **$x$**, características/features que se utilizan para hacer una\n\npredicción. Esto podría, por ejemplo, ser una imagen.\n\n  \n\n- $y$, clases/labels o categorías reales para ciertas características\n\n\"x\".\n\n  \n\n- $h$, es una predicción $x^{i}$ hecha por el modelo, para ciertos\n\nparámetros de ajuste $\\theta$.\n\n  \n\n- $\\theta$, son los parámetros a ajustar del Discriminador.\n\n  \n\n- $\\dfrac{-1}{m} \\sum_{i=1}^{m}$ es el promedio de la pérdida en un\n\nbatch completo, en donde el signo negativo es relevante para el\n\ncambio de signo y ajustar y obtener una pérdida siempre positiva.\n\n  \n\nDe acuerdo a la ecuación\n\n[\\[eq:cost_function\\]](#eq:cost_function){reference-type=\"ref\"\n\nreference=\"eq:cost_function\"}, se pueden distinguir claramente dos\n\npartes, en donde:\\\n\n**Parte $y^{i} log \\left( h(x^{i}, \\theta) \\right)$**, resumida en\n\nfigura [1.7](#fig:y_log){reference-type=\"ref\" reference=\"fig:y_log\"} y\n\ntabla [1.1](#table:y_log){reference-type=\"ref\" reference=\"table:y_log\"}.\n\n  \n\n- Predicción relevante sólo para cuando la clase $y=1$, debido a que\n\nfunción pérdida $J(\\theta) = 0$ para $y=0$.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 1$, entonces\n\n$log \\left(h(x^{i}, \\theta) \\right) \\approx 0$, y por lo tanto la\n\nfunción de pérdida $J(\\theta) \\approx 0$, porque predicción $h$ y\n\nclase $y$, son iguales o muy similares.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 0$, entonces\n\n$log \\left(h(x^{i}, \\theta) \\right) \\approx -\\infty$, y por lo\n\ntanto la función de pérdida $J(\\theta) \\approx -\\infty$, porque\n\npredicción $h$ y clase $y$, son distintas.\n\n  \n\n**Parte\n\n$\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$**,\n\nresumida en figura [1.8](#fig:1-y_log){reference-type=\"ref\"\n\nreference=\"fig:1-y_log\"} y tabla\n\n[1.2](#table:1-y_log){reference-type=\"ref\" reference=\"table:1-y_log\"}.\n\n  \n\n- Predicción relevante sólo para cuando la clase $y=0$, debido a que\n\nfunción pérdida $J(\\theta) = 0$ para $y=1$.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 0$, entonces\n\n$log \\left(1- h(x^{i}, \\theta) \\right) \\approx 0$, y por lo tanto\n\nla función de pérdida $J(\\theta) \\approx 0$, porque predicción $h$ y\n\nclase $y$, son iguales o muy similares.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 1$, entonces\n\n$log \\left(1- h(x^{i}, \\theta) \\right) \\approx -\\infty$, y por lo\n\ntanto la función de pérdida $J(\\theta) \\approx -\\infty$, porque\n\npredicción $h$ y clase $y$, son distintas.\n\n  \n\n::: {#table:y_log}\n\n$y^{i}$ $h(x^{i}, \\theta)$ $y^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\}$\n\n------- --------- -------------------- ------------------------------------------------ --\n\nFalso 0 \\- 0\n\nFalso 0 \\- 0\n\nReal 1 $\\approx$ 0.99 $\\approx 0$\n\nReal 1 $\\approx 0$ $\\approx - \\infty$\n\n  \n\n: Relación $y^{i} \\left\\{ h(x^{i}, \\theta) \\right\\}$ con\n\n$y^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\}$.\n\n:::\n\n  \n\n[\\[table:y_log\\]]{#table:y_log label=\"table:y_log\"}\n\n  \n\n![$J(\\theta)$ v/s\n\n$y^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\}$](img/fix0/cost-function-1){#fig:y_log}\n\n  \n\n::: {#table:1-y_log}\n\n$y^{i}$ $h(x^{i}, \\theta)$ $\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$\n\n------- --------- -------------------- ------------------------------------------------------------------ --\n\nReal 1 \\- 0\n\nReal 1 \\- 0\n\nFalso 0 $\\approx$ 0.01 $\\approx 0$\n\nFalso 0 $\\approx 1$ $\\approx - \\infty$\n\n  \n\n: Relación $y^{i} \\left\\{ h(x^{i}, \\theta) \\right\\}$ con\n\n$\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$.\n\n:::\n\n  \n\n[\\[table:1-y_log\\]]{#table:1-y_log label=\"table:1-y_log\"}\n\n  \n\n![$J(\\theta)$ v/s\n\n$\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$](img/fix0/cost-function-2){#fig:1-y_log}\n","properties":"\n","discussions":{},"comments":{},"hash":236186778,"tx":2262},"gkhFvwx0DRFTGKjR/syncedContent":{"id":"gkhFvwx0DRFTGKjR/syncedContent","type":"syncedContent","historyData":{"236186778":{"id":"gkhFvwx0DRFTGKjR/content","type":"content","text":"# Particularidades de una GAN\n\n  \n\nLa GAN está compuesta de 2 redes neuronales, un Discriminador y un\n\nGenerador. El Discriminador es un clasificador que se entrena para\n\ndeterminar la probabilidad de que cierta imagen sea falsa. Es decir,\n\nmodela la probabilidad de que cierto ejemplo sea falso, dadas ciertas\n\ncaracterísticas de entrada. Esto es, es la probabilidad de dado una\n\nimagen de entrada $X$, $Y$ sea falsa: $$\\begin{aligned}\n\nP(Y=clase | X=características)\\end{aligned}$$ Esta probabilidad es la\n\nque se envía como retroalimentación (feedback) al Generador para su\n\najuste de pesos.\\\n\nEl principal objetivo del Generador es producir ejemplos realistas de\n\nciertas clases. Es decir, intenta encontrar y modelar el espacio de las\n\nposibilidades de ciertas clases. Esto es, dado ciertas clases $Y$ (como\n\npor ejemplo, perro y/o gatos), se quiere obtener la probabilidad de\n\nciertas características $X$. $$\\begin{aligned}\n\nP(X= características | Y= clase )\\end{aligned}$$ Si el generador\n\nsolo se entrena para producir características relevantes de sólo una\n\nclase, entonces el Generador intenta modelar la probabilidad de ciertas\n\ncaracterísticas $X$, $P(X)$\\\n\nSi la clase $Y$ son por ejemplo perros, $P(X)$ intenta modelar y\n\naproximar la distribución real de probabilidad de características de\n\ntodos los posibles perros existentes.\n\n  \n\n#### Noise Vector, vector aleatorio z\n\n  \n\nIdealmente el Generador no produce el mismo ejemplo cada vez. para lo\n\nanterior se le da un set distinto de valores aleatorios, conocidos como\n\n\"noise vector\", o \"vector ruido\". Usualmente se generan de forma\n\naleatoria, tomando valores de forma uniforme entre 0 y 1 desde una\n\ndistribución normal. $$\\begin{aligned}\n\nZ \\sim N(0,1)\\end{aligned}$$\n\n  \n\nDebe de ser lo suficientemente grande para tener la mayor cantidad de\n\nposibilidades. Generalmente se toman vectores con dimensiones en base a\n\npotencias de 2.\\\n\nLa elección y/o generación del vector Z es una parte importante del\n\nGenerador, pues puede verse como una medida del balance entre la\n\nfidelidad y calidad de la generación, y la diversidad de esta.\n\n  \n\n- Si la muestra de Z se saca de una Distribución Normal, el modelo\n\nGenerador tiene más probabilidades de ver valores de Z dentro de\n\nmedia desviación estandar.\n\n  \n\n- Con lo anterior, durante el entrenamiento del Generador, el modelo\n\ntiende a familiarizarse más con ciertos *vectores de ruido\n\naleatorio*, modelando y generando areas que salen desde estos\n\nvectores más familiares y probables.\n\n  \n\n- En estas áreas, el modelo tenderá a tener resultados posiblemente\n\nmucho más realistas, pero tenderá a no generar nada fuera de lo\n\ncomún.\n\n  \n\nLo anterior, constituye por lo tanto un **balance entre fidelidad y\n\ndiversidad**, esto es, imágenes realistas y con gran calidad, versus\n\ndiversidad y variedad de imágenes.\n\n  \n\n#### Función de pérdida\n\n  \n\nLa función de pérdida u objetivo para una GAN definida en el paper\n\noriginal [@goodfellowGenerativeAdversarialNetworks2014] está dada como:\n\n$$\\begin{aligned}\n\nJ(\\theta) = \\dfrac{-1}{m} \\sum_{i=1}^{m} \\left[\n\ny^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\} +\n\n\\left( 1-y^{i} \\right) log \\left( 1 - \\left\\{ h(x^{i}, \\theta) \\right\\} \\right)\n\n\\right]\n\n\\label{eq:cost_function}\n\n\\end{aligned}$$\n\n  \n\nEn donde:\n\n  \n\n-  **$x$**, características/features que se utilizan para hacer una\n\npredicción. Esto podría, por ejemplo, ser una imagen.\n\n  \n\n- $y$, clases/labels o categorías reales para ciertas características\n\n\"x\".\n\n  \n\n- $h$, es una predicción $x^{i}$ hecha por el modelo, para ciertos\n\nparámetros de ajuste $\\theta$.\n\n  \n\n- $\\theta$, son los parámetros a ajustar del Discriminador.\n\n  \n\n- $\\dfrac{-1}{m} \\sum_{i=1}^{m}$ es el promedio de la pérdida en un\n\nbatch completo, en donde el signo negativo es relevante para el\n\ncambio de signo y ajustar y obtener una pérdida siempre positiva.\n\n  \n\nDe acuerdo a la ecuación\n\n[\\[eq:cost_function\\]](#eq:cost_function){reference-type=\"ref\"\n\nreference=\"eq:cost_function\"}, se pueden distinguir claramente dos\n\npartes, en donde:\\\n\n**Parte $y^{i} log \\left( h(x^{i}, \\theta) \\right)$**, resumida en\n\nfigura [1.7](#fig:y_log){reference-type=\"ref\" reference=\"fig:y_log\"} y\n\ntabla [1.1](#table:y_log){reference-type=\"ref\" reference=\"table:y_log\"}.\n\n  \n\n- Predicción relevante sólo para cuando la clase $y=1$, debido a que\n\nfunción pérdida $J(\\theta) = 0$ para $y=0$.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 1$, entonces\n\n$log \\left(h(x^{i}, \\theta) \\right) \\approx 0$, y por lo tanto la\n\nfunción de pérdida $J(\\theta) \\approx 0$, porque predicción $h$ y\n\nclase $y$, son iguales o muy similares.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 0$, entonces\n\n$log \\left(h(x^{i}, \\theta) \\right) \\approx -\\infty$, y por lo\n\ntanto la función de pérdida $J(\\theta) \\approx -\\infty$, porque\n\npredicción $h$ y clase $y$, son distintas.\n\n  \n\n**Parte\n\n$\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$**,\n\nresumida en figura [1.8](#fig:1-y_log){reference-type=\"ref\"\n\nreference=\"fig:1-y_log\"} y tabla\n\n[1.2](#table:1-y_log){reference-type=\"ref\" reference=\"table:1-y_log\"}.\n\n  \n\n- Predicción relevante sólo para cuando la clase $y=0$, debido a que\n\nfunción pérdida $J(\\theta) = 0$ para $y=1$.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 0$, entonces\n\n$log \\left(1- h(x^{i}, \\theta) \\right) \\approx 0$, y por lo tanto\n\nla función de pérdida $J(\\theta) \\approx 0$, porque predicción $h$ y\n\nclase $y$, son iguales o muy similares.\n\n  \n\n- Si la predicción $h(x^{i}) \\approx 1$, entonces\n\n$log \\left(1- h(x^{i}, \\theta) \\right) \\approx -\\infty$, y por lo\n\ntanto la función de pérdida $J(\\theta) \\approx -\\infty$, porque\n\npredicción $h$ y clase $y$, son distintas.\n\n  \n\n::: {#table:y_log}\n\n$y^{i}$ $h(x^{i}, \\theta)$ $y^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\}$\n\n------- --------- -------------------- ------------------------------------------------ --\n\nFalso 0 \\- 0\n\nFalso 0 \\- 0\n\nReal 1 $\\approx$ 0.99 $\\approx 0$\n\nReal 1 $\\approx 0$ $\\approx - \\infty$\n\n  \n\n: Relación $y^{i} \\left\\{ h(x^{i}, \\theta) \\right\\}$ con\n\n$y^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\}$.\n\n:::\n\n  \n\n[\\[table:y_log\\]]{#table:y_log label=\"table:y_log\"}\n\n  \n\n![$J(\\theta)$ v/s\n\n$y^{i} log \\left\\{ h(x^{i}, \\theta) \\right\\}$](img/fix0/cost-function-1){#fig:y_log}\n\n  \n\n::: {#table:1-y_log}\n\n$y^{i}$ $h(x^{i}, \\theta)$ $\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$\n\n------- --------- -------------------- ------------------------------------------------------------------ --\n\nReal 1 \\- 0\n\nReal 1 \\- 0\n\nFalso 0 $\\approx$ 0.01 $\\approx 0$\n\nFalso 0 $\\approx 1$ $\\approx - \\infty$\n\n  \n\n: Relación $y^{i} \\left\\{ h(x^{i}, \\theta) \\right\\}$ con\n\n$\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$.\n\n:::\n\n  \n\n[\\[table:1-y_log\\]]{#table:1-y_log label=\"table:1-y_log\"}\n\n  \n\n![$J(\\theta)$ v/s\n\n$\\left( 1-y^{i} \\right) log \\left( 1 - h(x^{i}, \\theta) \\right)$](img/fix0/cost-function-2){#fig:1-y_log}\n","properties":"\n","discussions":{},"comments":{},"hash":236186778}},"syncHistory":{"main":[236186778,null,236186778]},"v":1,"hash":1606547267581,"tx":2264},"syncData":{"id":"syncData","type":"data","data":{"1LtDdOilTCWAvx7SrDZVhfiIEKJ2B1AxU6gFrT9JG8rIucsLAxg":{"id":"1LtDdOilTCWAvx7SrDZVhfiIEKJ2B1AxU6gFrT9JG8rIucsLAxg","itemId":"Nxop4XKtLamIHaeN","type":"file","hash":-1618910401},"18Y7wb0W3yhMT1TQ-E5CjcqYpLDSaybnDL4fvHGH_GGClzF1O4Q":{"id":"18Y7wb0W3yhMT1TQ-E5CjcqYpLDSaybnDL4fvHGH_GGClzF1O4Q","itemId":"ngEhJlO2HTEBESzH","type":"file","hash":1423641658},"1QNPzd3MJZwgwA6mQ_CcSQXTTQiWe_6tua804hSfFOg8CKfQmQw":{"id":"1QNPzd3MJZwgwA6mQ_CcSQXTTQiWe_6tua804hSfFOg8CKfQmQw","itemId":"2uMtKUmHDISxs6dy","type":"file","hash":-453991916},"1IM9blyUzq_lcoOmnH9wKe2I36Dw6G1I-CZk_WHMWDUPS7Riwwg":{"id":"1IM9blyUzq_lcoOmnH9wKe2I36Dw6G1I-CZk_WHMWDUPS7Riwwg","itemId":"2uMtKUmHDISxs6dy/content","type":"content","hash":-415451179},"1MJfs3vl7rsFbKEmmra79i13gNhgnnHO_reOMjphnFSZ8Ude2KQ":{"id":"1MJfs3vl7rsFbKEmmra79i13gNhgnnHO_reOMjphnFSZ8Ude2KQ","itemId":"ngEhJlO2HTEBESzH/content","type":"content","hash":1223881783},"1HKg5j2RyL6h2gYmEuXbyN2N38g8raGIo9PGOYPONxVbFgoLBoQ":{"id":"1HKg5j2RyL6h2gYmEuXbyN2N38g8raGIo9PGOYPONxVbFgoLBoQ","itemId":"badgeCreations","type":"data","hash":-278927930},"16LE-E2fbxUqrmnnP-VpLOVADisH1cw8qRS-paPMDSP7sYDqVgw":{"id":"16LE-E2fbxUqrmnnP-VpLOVADisH1cw8qRS-paPMDSP7sYDqVgw","itemId":"t8aD6kgGQvq7Q4qZ/content","type":"content","hash":-601391086},"1O9AqBgN_uTh38KdSNlVR6XE7wEq9BceGNKoqaPhVuv8PEpHu9Q":{"id":"1O9AqBgN_uTh38KdSNlVR6XE7wEq9BceGNKoqaPhVuv8PEpHu9Q","itemId":"Nxop4XKtLamIHaeN/content","type":"content","hash":-601981126},"1bQOL7zwNq3rNPzJODBGsC7YoEXVTilcmr5KDfjpMvXBbhbR8mQ":{"id":"1bQOL7zwNq3rNPzJODBGsC7YoEXVTilcmr5KDfjpMvXBbhbR8mQ","itemId":"t8aD6kgGQvq7Q4qZ","type":"file","hash":1691181492},"1PNi3fjQInymDYA8INCfo2Jqmiih0BRCmapoQCsmGaXgEvULjOQ":{"id":"1PNi3fjQInymDYA8INCfo2Jqmiih0BRCmapoQCsmGaXgEvULjOQ","itemId":"templates","type":"data","hash":-972705388},"1QYnfo3a7o0ymZq_VL0NHOicOX_zGJPVFQd3ySX9IA3US_eQxtQ":{"id":"1QYnfo3a7o0ymZq_VL0NHOicOX_zGJPVFQd3ySX9IA3US_eQxtQ","itemId":"3Onhrwns2UKPGrmE/content","type":"content","hash":-131821423},"1-QQYOFOAixMNhQYOARxSXwjmpbGm53p_wXg6_2uxpHaj6fyPoQ":{"id":"1-QQYOFOAixMNhQYOARxSXwjmpbGm53p_wXg6_2uxpHaj6fyPoQ","itemId":"3Onhrwns2UKPGrmE","type":"file","hash":-585715289},"1TNmaQHQQWSdcB-laDBiNFUQbbTKScNYg1pdEioNv9dH5QpKpaQ":{"id":"1TNmaQHQQWSdcB-laDBiNFUQbbTKScNYg1pdEioNv9dH5QpKpaQ","itemId":"8qtJa4OoGIQAnMPI","type":"folder","hash":615584379},"1YnIdvHeglwJJX0O2ajKlFnW-gxddx5rhV97aaIOZaWaJhM2lDg":{"id":"1YnIdvHeglwJJX0O2ajKlFnW-gxddx5rhV97aaIOZaWaJhM2lDg","itemId":"sE8uhT86oltmXjsx/content","type":"content","hash":637348124},"1lN9lQe6q78nz4uVY5hBFMUttvUgKyf_Y1Up-ZpyShNsipvygnA":{"id":"1lN9lQe6q78nz4uVY5hBFMUttvUgKyf_Y1Up-ZpyShNsipvygnA","itemId":"sE8uhT86oltmXjsx","type":"file","hash":1285508111},"1Ylv3av4BOnSc6x545mgMvwETIrETEoytbaOm21P8tKoDPe3eAA":{"id":"1Ylv3av4BOnSc6x545mgMvwETIrETEoytbaOm21P8tKoDPe3eAA","itemId":"4nVfhBNx6GrFL2GA","type":"folder","hash":1490316995},"1Lt2Nzsu69q9x3gVVLX8uxRKl41eQcTvj-XIZN6igKrPsJ2CDBA":{"id":"1Lt2Nzsu69q9x3gVVLX8uxRKl41eQcTvj-XIZN6igKrPsJ2CDBA","itemId":"gkhFvwx0DRFTGKjR/content","type":"content","hash":236186778},"1Nn730EEz23qQKp0Ink8bO9M9Iqx6lkLCdc_iy5sE15jO_aO2Gw":{"id":"1Nn730EEz23qQKp0Ink8bO9M9Iqx6lkLCdc_iy5sE15jO_aO2Gw","itemId":"gkhFvwx0DRFTGKjR","type":"file","hash":-628255140}},"hash":1020502923,"tx":2267},"localSettings":{"id":"localSettings","type":"data","data":{"welcomeFileHashes":{"1789794481":1},"filePropertiesTab":"simple","htmlExportTemplate":"styledHtml","pdfExportTemplate":"styledHtml","pandocExportFormat":"pdf","googleDriveRestrictedAccess":false,"googleDriveFolderId":"","googleDriveWorkspaceFolderId":"","googleDrivePublishFormat":"markdown","googleDrivePublishTemplate":"styledHtml","bloggerBlogUrl":"","bloggerPublishTemplate":"plainHtml","dropboxRestrictedAccess":false,"dropboxPublishTemplate":"styledHtml","githubRepoFullAccess":false,"githubRepoUrl":"","githubWorkspaceRepoUrl":"","githubPublishTemplate":"jekyllSite","gistIsPublic":false,"gistPublishTemplate":"plainText","gitlabServerUrl":"","gitlabApplicationId":"","gitlabProjectUrl":"","gitlabWorkspaceProjectUrl":"","gitlabPublishTemplate":"plainText","wordpressDomain":"","wordpressPublishTemplate":"plainHtml","zendeskSiteUrl":"","zendeskClientId":"","zendescPublishSectionId":"","zendescPublishLocale":"","zendeskPublishTemplate":"plainHtml","syncSub":"117349469283779987429","syncStartPageToken":"289560"},"hash":-1043865296,"tx":2269},"2uMtKUmHDISxs6dy/syncedContent":{"id":"2uMtKUmHDISxs6dy/syncedContent","type":"syncedContent","historyData":{"-415451179":{"id":"2uMtKUmHDISxs6dy/content","type":"content","text":"# Una introducción a las Redes Generativas Adversarias\n\n  \n\n## GANs: Generative Adversarial Networks\n\n  \n\nLas Redes Generativas Adversariales, o GANs, fueron descritas por primera vez el 2014 en el artículo de Ian Goodfellow, \"Generative Adversarial Networks\". Son una clase dentro de las técnicas del Machine Learning que permiten la generación de imagénes sintéticas, forzando las imágenes sintéticas generadas a ser estadísticamente indistinguibles de las imágenes originales. La gran capacidad de generación y la potencia de la idea de las redes adversariales generativas ha hecho que en los últimos años se haya puesto el foco en su investigación y en la generación de nuevas arquitecturas.\n\nLas GANs consisten básicamente en dos redes que compiten mutuamente: una **red genera datos falsos**, y otra que **intenta distinguir los datos falsos de los reales**.\n\nDe esta forma, las GANs:\n- Es un modelo _generativo_ porque tiene como proposito el generar nuevos datos.\n- Son _redes_ porque fundamentalmente la arquitectura está compuesta de dos redes neuronales; **Discriminador** y **Generador**.\n- Son _adversarias o antagónicas_ debido a que el Discriminador compite con el Generador.\n\n  \n\n## Funcionamiento de las GAN\nLas GANs constan en su forma más básica de dos redes neuronales, _Generador_ y _Discriminador_. De acuerdo a lo anterior, los aspectos básicos y fundamentales de estas redes son:\n### Generador\n- Tiene como **entrada** un vector de números aleatorios, seleccionado de un espacio latente predefinido, como una función normal multivariada.\n- La **salida** es un ejemplo sintetizado falso que intenta ser estadísticamente lo más parecido a un ejemplo real.\n- El **objetivo** es generar datos falsos que sean indistinguibles de los datos reales.\n\n### Discriminador\n\n  \n\n- Tiene como **entradas**\n\n- Los datos reales, que provienen de la base de datos de entrenamiento.\n\n- Los datos falsos, sintetizados por el Discriminador.\n\n- La **salida** es la probabilidad del ejemplo de entrada de ser real.\n\n- El **objetivo** es distinguir los datos falsos provenientes del Generador y los datos reales provenientes de la base de datos.\n\n  \n\nDe esta forma, se definen:\n\n  \n\n-  **Conjunto de entrenamiento:** Base de datos de ejemplos reales. El Generador debe aprender a emular de forma\n\nperfecta estos datos. Estos datos sirven como entrada a la red Discriminador.\n\n-  **Vector de ruido aleatorio:** Vector **z** de entrada a la red Generador. Esta entrada es utilizada por el Generador como punto de partida para la síntesis de datos falsos.\n\n-  **Red Generadora:** Toma como entrada un vector de números aleatorio **z**, y genera como salida un dato\n\nfalso **x\\***. El objetivo es que el dato falso sea indistinguible del dato real.\n\n-  **Red Discriminadora:** Toma como entrada un dato real **x** o un dato falso **x\\***. El objetivo es determinar, para cada dato, la probabilidad si es real.\n\n-  **Proceso iterativo de entrenamiento/sintonización:** Para cada una de las predicciones del Discriminador,\n\nse determina lo buena o no de esta, y se utiliza el resultado para volver a sintonizar la red Discriminadora\n\ny Generadora mediante _Propagación hacia atrás_ (Backpropagation).\n  \n\n- **Conjunto de entrenamiento:** Base de datos de ejemplos reales. El Generador debe aprender a emular de forma perfecta estos datos. Estos datos sirven como entrada a la red Discriminador.\n- **Vector de ruido aleatorio:** Vector **z** de entrada a la red Generador. Esta entrada es utilizada por el Generador como punto de partida para la síntesis de datos falsos.\n- **Red Generadora:** Toma como entrada un vector de números aleatorio **z**, y genera como salida un dato falso **x\\***. El objetivo es que el dato falso sea indistinguible del dato real.\n- **Red Discriminadora:** Toma como entrada un dato real **x** o un dato falso **x\\***. El objetivo es determinar, para cada dato, la probabilidad si es real.\n- **Proceso iterativo de entrenamiento/sintonización:** Para cada una de las predicciones del Discriminador, se determina lo buena o no de esta, y se utiliza el resultado para volver a sintonizar la red Discriminadora y Generadora mediante _Propagación hacia atrás_ (Backpropagation).\n\n##  Proceso básico de entrenamiento\n\nEl algorítmo de entrenamiento para una GAN para cada uno de los ciclos de iteración es como sigue:\n- Entrenamiento del _Discriminador_:\n\t- Se toma una muestra aleatoria **x** desde el conjunto de entrenamiento.\n\t- Se obtiene un nuevo vector aleatorio **z**, y usando la red del Generador se sintetiza un ejemplo falso **x\\***.\n\t- Se usa la red del Discriminador para clasificar **x** y **x\\***.\n\t- Se calculan los errores de clasificación y se propaga hacia atras (backpropagation) el error total para actualizar los parámetros de entrenamiento del Discriminador, intentando minimizar el error de clasificación.\n- Entrenamiento del _Generador_:\n\t- Se toma un nuevo vector aleatorio **z**, y se usa la red del Generador para sintetizar un ejemplo falso **x\\***.\n\t- Se usa el Discriminador para clasificar **x**.\n\t- Se calculan los errores de clasificación y se propaga hacia atras (backpropagation) el error para actualizar los parámetros de entrenamiento del Generador, intentando maximizar el error del Discriminador.\n\n  \n\nDebido a que este proceso de entrenamiento es iterativo, cada vez que el _Discriminador_ es entrenado y mejora respecto al _Generador_, el _Generador_ es actualizado y mejora en el proceso.\nLo anterior, en palabras más simples, se debe a que el _Generador_ y el _Discriminador_ están inmersos en un _juego de suma cero_, debido a que cada red tiene como objetivo mejorar respecto a la otra, haciendo que la otra red empeore. Esto lleva a que la arquitectura deba tender a un punto de _equilibrio_, en el cual ninguna de las dos pueda seguir mejorando.\n\nDe acuerdo Ian Goodfellow, teóricamente para cada red _Generador_ existe una única red _Discriminador_ óptima. Se muestra también que el _Generador_ es óptimo cuando el _Discriminador_ alcanza predicciones de un valor de 0.5 para todas las entradas. Es decir, el _Generador_ es óptimo cuando el _Discriminador_ está completamente confundido y es incapaz de distinguir entre datos reales y datos falsos.\n\nSin embargo, alcanzar el _equilibrio_ para una GAN, significa en la práctica alcanzar el **Equilibrio de Nash** para un caso en el que no existen algorítmos, en donde las *funciones de costo* son no convexas y el espacio de parámetros es de altas dimensiones. Debido a lo anterior, la utilización de **Gradiente Descendiente** no garantiza su convergencia, y se han desarrollado diversas arquitecturas y \"trucos\" de entrenamiento heurístico para alcanzar la convergencia.\n\nPara una explicación más detallada del funcionamiento de las GANs, se recomienda el artículo de Ian Goodfellow, \"Generative Adversarial Network\", el tutorial realizado en la conferencia NIPS de 2016 por él mismo y el Workshop realizado en la misma conferencia disponible en video.\n","properties":"\n","discussions":{},"comments":{},"hash":-415451179}},"syncHistory":{"main":[-415451179,-415451179,null]},"v":1,"hash":1606547291304,"tx":2270},"gkhFvwx0DRFTGKjR/contentState":{"id":"gkhFvwx0DRFTGKjR/contentState","type":"contentState","selectionStart":0,"selectionEnd":0,"scrollPosition":{"sectionIdx":0,"posInSection":0},"hash":1606547313946,"tx":2275},"lastOpened":{"id":"lastOpened","type":"data","data":{"3Onhrwns2UKPGrmE":1606476285128,"Nxop4XKtLamIHaeN":1606545381248,"ngEhJlO2HTEBESzH":1606545383166,"t8aD6kgGQvq7Q4qZ":1606542709841,"sE8uhT86oltmXjsx":1606543321457,"2uMtKUmHDISxs6dy":1606547315107,"gkhFvwx0DRFTGKjR":1606547313997},"hash":-306634341,"tx":2276},"2uMtKUmHDISxs6dy/contentState":{"id":"2uMtKUmHDISxs6dy/contentState","type":"contentState","selectionStart":1,"selectionEnd":1,"scrollPosition":{"sectionIdx":0,"posInSection":0},"hash":1606547321592,"tx":2280}}
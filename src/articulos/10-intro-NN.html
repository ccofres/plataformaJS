<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      href="https://fonts.googleapis.com/css2?family=Oswald&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Orbitron&display=swap"
      rel="stylesheet"
    />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link
      href="https://fonts.googleapis.com/css2?family=Merriweather&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="../../css/styles.css" />
    <link rel="stylesheet" href="../../css/art-styles.css" />
    <link rel="stylesheet" href="../../css/style-sidebar.css" />
    <title>Template</title>
  </head>
  <body>
    <!-- THE HEADER - SECOND HEADER-->
    <div id="the-header">
      <header>
        <div class="second-header">
          <h1><a href="../../index.html"> Plataforma JS </a></h1>
        </div>
      </header>
    </div>

    <!-- NAV -  BARRA NAVEGACION-->
    <div id="the-nav">
      <nav>
        <ul id="menu">
          <!--           <li><a href="../../../index.html">Home</a></li> -->
          <li class="dropdown">
            <a href="javascript:void(0)" class="dropbtn">Let's play!</a>
            <div class="dropdown-content">
              <a href="../modelos.html">Modelos</a>
              <a href="../editorjs.html">Editor JS</a>
            </div>
          </li>

          <li class="dropdown">
            <a href="../tensorflowjs/index-tfjs.html" class="dropbtn"
              >TensorFlow.js</a
            >
            <!-- <div class="dropdown-content">
              <a href="./src/tensorflowjs/index-tfjs.html"
                ></a
              >
              <a href="./src/tensorflowjs/recursos.html">Otros recursos</a>
            </div> -->
          </li>
          <li>
            <a style="cursor: pointer" onclick="openNav()">&#9776; Ejemplos</a>
          </li>

          <li class="dropdown">
            <a href="javascript:void(0)" class="dropbtn">Recursos externos</a>
            <div class="dropdown-content">
              <a href="https://js.tensorflow.org/api/latest/" target="_blank"
                >Referencia API</a
              >

              <a
                href="https://github.com/tensorflow/tfjs-models"
                target="_blank"
                >Modelos tfjs</a
              >
              <a
                href="https://github.com/tensorflow/tfjs-examples/"
                target="_blank"
                >Más ejemplos tfjs</a
              >
              <a
                href="https://blog.tensorflow.org/search?label=TensorFlow.js&max-results=10"
                target="_blank"
                >Blog TensorFlow.js</a
              >
              <a href="https://playground.tensorflow.org/" target="_blank"
                >Tensorflow Playground</a
              >
              <a href="https://poloclub.github.io/ganlab/" target="_blank"
                >GAN Lab</a
              >
            </div>
          </li>
        </ul>
      </nav>
    </div>

    <div class="control-buttons-up">
      <div class="control-buttons-up-left">
        <a href="../modelos.html" title="Modelos"> &#9776;Menú</a>
      </div>
      <div class="control-buttons-up-left">
        <a
          href="./01-breve-historia.html"
          title="Breve historia de la IA y el Aprendizaje Profundo"
        >
          &laquo;Back</a
        >
      </div>
      <div class="control-buttons-up-right">
        <a
          href="./20-intro-CNN.html"
          title="Introducción a las Redes Neuronales Convolucionales"
        >
          Next&raquo;
        </a>
      </div>
    </div>
    <!-- contenido HTML-->
    <div id="contenido-html">
      <div class="art-html">
        <h1 id="introducción-a-redes-neuronales">
          Introducción a Redes Neuronales
        </h1>
        <h2 id="redes-neuronales">Redes Neuronales</h2>
        <p>
          Las redes neuronales, tienen su inspiración en la neurona biológica.
          Es por esto, que el nombre correcto para referirse a ellas es “Redes
          Neuronales Artificiales”.
        </p>
        <p>
          Las redes neuronales artificiales están en el centro del Aprendizaje
          Profundo, y tienen como primer modelo el propuesto en 1943 por Pitts y
          McCulloch. Este primer modelo propuesto, conocido como “Threshold
          Logic Unit”, era un modelo simple de una neurona biológica, de tipo
          binario, en donde cada neurona tenía un umbral prefijado. Tenía
          <strong>una o más entradas binarias</strong>, y
          <strong>una salida binaria</strong>. La neurona artificial activa su
          salida cuando al menos cierto número de entradas estan activas. Este
          modelo era capáz de aprender funciones de lógica binaria como AND y
          OR, y sirvió de base para modelos posteriores como el Perceptron y el
          Perceptron Multicapa.
        </p>
        <h3 id="el-perceptron">El Perceptron</h3>
        <p>
          Es un modelo propuesto en 1957 por Frank Rosenblatt, usado para
          clasificación binaria. Básicamente, es un tipo de neurona artificial
          en donde:
        </p>
        <ul>
          <li>
            Las entradas, a diferencia del TLU, son simple números en vez de
            valores binarios.
          </li>
          <li>
            La <strong>función sumatoria</strong> es la sumatoria lineal de las
            entradas o
            <strong
              >producto puntro entre las entradas y sus pesos asociados</strong
            >
            <p>
              $$\sum_{i=1}^{n}x_{i} \cdot w_{i} =
              x_{1}w_{1}+x_{2}w_{2}+x_{3}w_{3}+ \ldots +x_{n}w_{n}$$
            </p>
          </li>
          <li>
            La <strong>función de activación</strong> es la función escalón o
            <strong>Heaviside</strong> con un valor umbral típico de $0.5$.
          </li>
        </ul>
        <div class="img-contenedor">
          <a href="https://imgur.com/WS4gqql"
            ><img
              src="https://i.imgur.com/WS4gqql.jpg"
              title="Estructura básica de una neurona"
          /></a>
          <p>Estructura básica de una neurona</p>
        </div>
        <p>
          De esta forma, si la sumatoria lineal de las entradas, esto es,
          <strong
            >el producto punto entre las entradas y sus pesos asociados</strong
          >
          es:
        </p>
        <ul>
          <li>
            mayor al <em>valor umbral de la función escalón</em>, la salida del
            Perceptron será 1.
          </li>
          <li>
            menor al <em>valor umbral de la función escalón</em>, la salida del
            Perceptron será 0.
          </li>
        </ul>
        <p>La lógica de aprendizaje del Perceptron es:</p>
        <ol>
          <li>
            Se calcula la sumatoria entre entradas y sus pesos asociados. Esta
            <em>función sumatoria</em> es aplicada a la
            <em>función de activación</em> para generar una predicción
            <strong>$\hat{y}$</strong>. Este proceso es llamado
            <strong>FeedForward</strong>.
          </li>
          <li>
            Se compara la predicción hecha con la etiqueta correcta, para
            calcular el error:
            <p>$$ error = y- \hat{y} $$</p>
          </li>
          <li>
            Se actualizan los pesos intentando minimizar el error. Para esto se
            utiliza una
            <strong>Función de Pérdida como el MSE (Mean square error)</strong>,
            de esta forma se mejora la predicción intentando que el error sea lo
            más cercano a 0.
          </li>
          <li>Se repite el proceso desde el paso 1.</li>
        </ol>
        <p><strong>Una nota sobre el Perceptron</strong></p>
        <ul>
          <li>
            Como el perceptron implementa una sumatoria lineal de las entradas,
            <strong>es en sí un modelo de función lineal</strong>.
          </li>
          <li>
            Dado lo anterior, el Perceptron producirá una
            <strong>línea recta</strong> que “separa” o clasifica cierta parte
            de los datos.
          </li>
          <li>
            De esta forma, si el problema es lineal, o
            <strong>linealmente separable</strong>, es decir los datos pueden
            ser separados por una línea recta, el Perceptron funciona bien.
          </li>
          <li>
            Si los datos son no-lineales, el Perceptron fallará como modelo.
          </li>
        </ul>
        <h3 id="el-perceptron-multicapa">El Perceptron Multicapa</h3>
        <p>
          El Multilayer Perceptron (MLP), o Perceptron Multicapa, son redes
          neuronales con una capa de entrada (Input Layers), una o más capas
          ocultas (Hidden Layers) y una capa de salida (Output Layer) compuestas
          de Perceptrones. Cada una de sus capas, a excepción de la capa de
          salida, tiene cada una de sus neuronas conectada a cada una de las
          neuronas de la capa siguiente.
        </p>

        <div class="img-contenedor">
          <a href="https://imgur.com/To5a8yS"
            ><img
              src="https://i.imgur.com/To5a8yS.jpg"
              title="Capas de una Red Neuronal"
          /></a>
          <p>Capas de una Red Neurona</p>
        </div>
        <p>
          Una red es <strong>densa</strong> o <strong>Fully connected</strong>,
          cuando cada uno de los nodos o neuronas de una capa está conectado a
          todos los nodos o neuronas de la siguiente capa. Esta arquitectura es
          conocida como <strong>fully connected network</strong> y es la
          arquitectura más básica de redes neuronales. Es posible referirse a
          ella usualmente como <em>Red Neuronal Artificial</em>,
          <em>Multilayer Perceptron</em> (MLP),
          <em>Fully connected network</em> o <em>Feedforward network</em>.
        </p>

        <div class="img-contenedor">
          <a href="https://imgur.com/Fj7BwVo"
            ><img
              src="https://i.imgur.com/Fj7BwVo.png"
              title="Red Fully Connected"
          /></a>
          <p>Red Fully Connected</p>
        </div>
        <p>
          Este tipo de Red Fully Connected, se definen en TensorFlow.js
          utilizando la función &nbsp
          <code>tf.layers.dense</code>:
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L44-51&style=gruvbox-dark&showLineNumbers=on"></script>
        <p>
          Cada neurona en el Perceptron Multicapa es similar al Perceptron, pero
          tiene la flexibilidad de elegir el tipo de función de activación a
          usar, y de esta forma añade la posibilidad de representar funciones de
          activación más complejas.
        </p>
        <p>
          Al encadenar varios perceptrones, sólo se terminan obteniendo
          transformaciones lineales, incapaces de afrontar datos no-lineales. De
          esta forma, una red neuronal profunda con funciones de activación
          no-lineales puede teóricamente ser capáz de aproximar cualquier
          función continua, y con esto, afrontar y resolver problemas más
          complejos.
        </p>

        <br />
        <br />
        <br />
        <hr class="rounded" />
        <hr class="rounded" />
        <br />
        <br />
        <br />

        <h2 id="el-proceso-de-entrenamiento">El proceso de entrenamiento</h2>
        <p>
          El proceso de entrenamiento de una red neuronal, consiste básicamente
          en encontrar y aprender los valores de los pesos de todas las capas de
          la red que minimicen la función de pérdida, y por lo tanto, ajusten
          las predicciones de los datos de entrada con sus verdaderas etiquetas.
          Este proceso, es un proceso iterativo compuesto de una
          <em>propagación hacia adelante</em>,
          <em>forward propagation o feedforward</em>, y una
          <em>propagación hacia atrás</em>,
          <em>retropropagación o backpropagation</em>.
        </p>
        <p>
          En la primera fase, de <em>feedforward o forward propagation</em>, la
          información o datos de entrenamiento fluyen a través de la red desde
          la capa de entrada a la capa de salida en donde se calculan las
          predicciones. Estos datos pasan a través de la red, en donde cada
          neurona aplica su transformación a la información que recibe de las
          neuronas de la capa anterior y la envía a las neuronas de la capa
          siguiente. Cuando se llega a la capa final, se genera una predicción
          de la etiqueta para los datos o ejemplos de entrada.
        </p>
        <p>
          Con la predicción de la etiqueta, se utiliza una
          <strong>función de pérdida</strong> como medida y estimación del error
          en la predicción. Esta <strong>función de pérdida</strong> tomas las
          predicciones que realiza la red y los valores reales, y calcula qué
          tan bueno o mala fue la predicción. De esta forma, se mide lo lejos
          que está cada predicción respecto a lo que se esperaba obtener.
        </p>
        <p>
          Con la <em>estimación del error</em>, se inicia la propagación hacia
          atras o segunda fase llamada <em>backpropagation</em>, en donde se
          llama al <strong>optimizador</strong> para la actualización y ajuste
          de los <em>pesos</em> de la red, en la dirección del gradiente que
          <em>reduce esta pérdida o error</em> y por lo tanto minimiza la
          <strong>función de pérdida</strong>.
        </p>
        <p>
          Esta información se propaga hacia todas las neuronas que contribuyen
          directamente a la salida, basándose en la contribución relativa que
          haya aportado cada neurona.
        </p>
        <p>
          El optimizador ajusta los pesos de cada neurona con la ayuda del
          cálculo del gradiente de la función de pérdida en pequeños pasos o
          <em>steps</em>, dado por el <em>Learning Rate</em> o
          <em>Tasa de Aprendizaje</em>. La actualización de los pesos se hace
          generalmente en lotes o batches, capa por capa, hasta que todas las
          neuronas de la red hayan sido actualizadas.
        </p>

        <div class="img-contenedor">
          <a href="https://imgur.com/altrQa5"
            ><img
              src="https://i.imgur.com/altrQa5.jpg"
              title="Proceso de entrenamiento"
          /></a>
          <p>Proceso de entrenamiento</p>
        </div>

        <br />
        <br />
        <br />
        <hr class="rounded" />
        <hr class="rounded" />
        <br />
        <br />
        <br />

        <h2 id="términos-básicos">Términos básicos</h2>
        <ul>
          <li>
            <strong>Modelo</strong>: se entiende como la relacióne entre los
            atributos y la etiqueta.
          </li>
          <li>
            <strong>Atributos</strong>: son las variables de entrada a la red o
            modelo.
          </li>
          <li>
            <strong>Clases</strong>: es un set de posibles etiquetas a escoger
            en un problema de clasificación. De esta forma, si se están
            clasificando imagenes de perro y gatos, <em>perro</em> y
            <em>gato</em> son sus dos clases.
          </li>
          <li>
            <strong>Label, etiqueta o target</strong>: es el valor a predecir.
            Este puede ser una categoría o clasificación a predecir, como el
            tipo de animal en una imagen. Es una instancia específica de una
            clase, es decir, si una imagen tiene una clase específica
            <em>perro</em>, entonces <em>perro</em> es la etiqueta de esa
            imagen-ejemplo.
          </li>
          <li>
            <strong>Ejemplo etiquetado</strong>: es una instancia que incluye
            los atributos y su correspondiente etiqueta.
          </li>
          <li>
            <strong>Ejemplo sin etiqueta</strong>: es una instancia que incluye
            solo los atributos, sin la etiqueta correspondiente.
          </li>
          <li>
            <strong>Mini-batch o Batch</strong>: los minilotes o lotes de datos
            son pequeños set de muestras o ejemplos que son procesados
            simultáneamente por el modelo. El número de muestras o ejemplos es
            usualmente una potencia de 2, típicamente entre 8 a 128, para
            facilitar la asignación de recursos en memoria. Durante el
            entrenamiento, un minilote (mini-batch) es usado para calcular el
            gradiente descendiente y actualizar los pesos del modelo.<br />
            Tamaños de minilotes más grandes ayudan a un entrenamiento y
            aprendizaje más rápido, pero requieren mayor espacio en memoria. Un
            tamaño por default recomendado es 32.
          </li>
          <li>
            <strong>Entrenamiento</strong>: es el proceso de aprendizaje gradual
            mediante el cual se relacionan los atributos y sus respectivas
            etiquetas.
          </li>
          <li>
            <strong>Inferencia o predicción</strong>: es la aplicación de un
            modelo entrenado a ejemplos sin etiqueta.
          </li>
          <li>
            <strong>Clasificación</strong>: es una tarea típica dentro del
            aprendizaje supervisado en donde se predicen <em>clases</em> dados
            ciertos atributos.
          </li>
          <li>
            <strong>Regresión</strong>: tarea típica dentro del aprendizaje
            supervisado en donde se predicen valores continuos, como el precio
            de una casa o un auto, dados ciertos atributos usados como
            <em>predictores</em>.
          </li>
        </ul>
        <h3 id="problemas-lineales-vs-no-lineales">
          Problemas lineales vs no-lineales
        </h3>
        <p>
          Los problemas dependiendo el tipo de datos, pueden ser clasificados en
          lineales y no lineales. Estos se describen a continuación.
        </p>
        <ul>
          <li>
            <strong>Si un problema es lineal</strong>, viene a significar que
            los datos pueden ser separados por una simple línea recta, y por lo
            tanto, el problema podría ser abordado con un simple Perceptron con
            función de activación lineal.
          </li>
        </ul>

        <div class="img-contenedor">
          <a href="https://imgur.com/yqqzXUx"
            ><img
              src="https://i.imgur.com/yqqzXUx.png"
              title="Datos de problema lineal"
          /></a>
          <p>Datos de problema lineal</p>
        </div>
        <ul>
          <li>
            <strong>Si el problema es no lineal</strong>, los datos no pueden
            ser separados por una simple línea recta, por lo que se necesita más
            de una línea recta para separar los datos. De esta forma, este tipo
            de problemas debe ser abordados al menos mediante Perceptrones
            Multicapa, con posibles funciones de activación no lineales para
            mejores rendimientos.
          </li>
        </ul>

        <div class="img-contenedor">
          <a href="https://imgur.com/At2yhUV"
            ><img
              src="https://i.imgur.com/At2yhUV.png"
              title="Datos de problema no lineal"
          /></a>
          <p>Datos de problema no lineal</p>
        </div>

        <br />
        <br />
        <br />
        <hr class="rounded" />
        <hr class="rounded" />
        <br />
        <br />
        <br />

        <h2>Hiperparámetros</h2>
        <p>
          Los hiperparámetros son ciertos valores de la configuración utilizada
          durante el proceso de entrenamiento. Son valores que generalmente no
          se obtienen de los datos, por lo que deben ser indicados y ajustados.
        </p>
        <p>
          A continuación se mencionan algunos posibles parámetros usuales a
          ajustar.
        </p>
        <h2 id="funciones-de-activación">Funciones de Activación</h2>
        <p>
          Las funciones de activación son a veces llamadas
          <em>funciones de transferencia</em> o <em>no linearidades</em>, porque
          transforman la combinación lineal de las entradas y sus pesos
          asociados a una forma no lineal.<br />
          Estas funciones de activación se ubican al final de cada Perceptron o
          neurona artificial, y es la forma de activar neurona.
        </p>
        <p>
          Se definen en TensorFlow.js al momento de agregar una capa mediante la
          etiqueta &nbsp
          <code>activation </code>
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L44-51&style=gruvbox-dark&showLineNumbers=on"></script>

        <ul>
          <li><strong>¿Por qué se utilizan?</strong></li>
        </ul>
        <p>
          Se utilizan para introducir no linearidades, y de esta forma, dotar a
          la red de la capacidad de afrontar problemas no lineales. Sin una
          función de activación no-lineal, un Perceptron Multicapa sin importar
          su cantidad de capas ocultas, se comportará de forma similar a un
          simple Perceptron. Esto es debido a que la combinación de
          <em>funciones de activacion lineales</em>, es simplemente otra función
          lineal. <br />
          Al mismo tiempo, se utilizan para restringir los valores de salida de
          cada neurona dentro de un rango finito.
        </p>
        <p>
          Existe una gran cantidad de funciones de activación, sin embargo, las
          que se utilizan más comunmente son pocas. Entre las más usadas están
          las siguientes:
        </p>
        <h3 id="función-lineal">Función Lineal</h3>
        <p>
          La función lineal, muchas veces utilizada como una
          <em>función identidad</em> pasando la señal inalterada. Es decir, la
          <em>salida</em> de la función de activación es igual a su entrada, y
          de esta forma, es como si no hubiera una función de activación. En el
          mejor de los casos, dependiendo el tipo de función lineal, sólo se
          escala la salida de la <em>función sumatoria</em>, sin la capacidad de
          transformar esta entrada en una función no lineal.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L52-53&style=gruvbox-dark&showLineNumbers=on"></script>

        <div class="img-contenedor">
          <a href="https://imgur.com/MYDv3zG"
            ><img src="https://i.imgur.com/MYDv3zG.png" title="Función Lineal"
          /></a>
          <p>Función Lineal tipo $f(x) = x$</p>
        </div>

        <h3 id="función-step-heaviside-o-escalón">
          Función Step, Heaviside, o escalón
        </h3>
        <p>
          La función escalón unitario produce una salida binaria. Es una función
          simple, en la que básicamente:
        </p>
        <ul>
          <li>
            <p>Si $x&gt;0$, la salida es $1$</p>
          </li>
          <li>
            <p>Si $x&lt;0$, la salida es $0$</p>
          </li>
        </ul>
        <p>
          Esta función es utilizada debido a su tipo de salida, en problemas de
          clasificación binaria del tipo verdadero o falso.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L55-56&style=gruvbox-dark&showLineNumbers=on"></script>

        <div class="img-contenedor">
          <a href="https://imgur.com/F0j1evV"
            ><img
              src="https://i.imgur.com/F0j1evV.png"
              title="Función Step, Heaviside o Escalón"
          /></a>
          <p>Función Step, Heaviside o Escalón</p>
        </div>

        <h3 id="función-sigmoide-o-logística">Función Sigmoide o Logística</h3>
        <p>
          La función Sigmoide es una de las más comunmente utilizadas. Su uso es
          común en problemas de clasificación binaria en donde lo que se quiere
          es predecir la probabilidad de una clase
          <em>en problemas en donde existen 2 clases</em>.
        </p>
        <p>
          La función toma todos los valores de entrada, y los reduce a un rango
          $[0,1]$, convirtiendo valores continuos entre $-\infty$ y $+\infty$ en
          una simple probabilidad entre $0$ y $1$.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L58-59&style=gruvbox-dark&showLineNumbers=on"></script>

        <div class="img-contenedor">
          <a href="https://imgur.com/WOyjAH6"
            ><img
              src="https://i.imgur.com/WOyjAH6.png"
              title="Función Sigmoide o Logística"
          /></a>
          <p>Función Sigmoide o Logística</p>
        </div>

        <h3 id="función-softmax">Función Softmax</h3>
        <p>
          La función Softmax es una generalización de la
          <strong>función sigmoide</strong>, y por esto es utilizada en
          problemas de clasificación para obtener las probabilidades de una
          clase cuando <em>el problema tiene más de 2 clases</em>. Esta función
          de activación, fuerza la salida de la red en el rango 0 a 1. Para
          esto, implementa la siguiente ecuación:
        </p>
        $$ \sigma(x_{n}) = \frac{e^{x_{n}}} {\sum_{i} e^{x_{i}} }$$

        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L61-62&style=gruvbox-dark&showLineNumbers=on"></script>

        <p>
          La función Softmax es la función aconsejada para problemas de
          clasificación de más de dos clases, o incluso donde existen sólo dos
          clases en donde se comporta simplemente como una Sigmoide.
        </p>
        <h3 id="función-tangente-hiperbólica">Función Tangente Hiperbólica</h3>
        <p>
          La función tangente hiperbólica es una versión
          <em>desplazada</em> de la función sigmoide. De esta forma, en vez de
          reducir los valores de entrada a un rango $[0,1]$, esta función lleva
          estos valores al rango $[-1,1]$.
        </p>
        <p>
          Esta función trabaja relativamente mejor que una función sigmoide en
          las
          <em>capas ocultas</em>, debido a que al llevar los valores al rango
          $[-1,1]$ tiene el efecto de centrar los datos, haciendo que el
          promedio esté cercano a $0$ (en la sigmoide el promedio está en
          $0.5$), haciendo que el aprendizaje para la capa posterior (o
          siguiente) sea un poco más fácil.
        </p>
        <p>La función Tangente Hiperbólica esta dada por:</p>
        $$ tanh(n) = \frac{e^{n} - e^{-n} } { e^{n} + e^{-n} }$$
        <p>
          Esta función, al igual que la función sigmoide, tiene como principal
          contra la saturación que ocurre para valores muy grandes (tanto
          positivos como negativos). Esto provoca que las derivadas locales, es
          decir, el <em>gradiente</em>, sea muy cercano a $0$, y por lo tanto al
          momento de la
          <em>Propagación hacia atras</em> (<strong>Backpropagation</strong>)
          casi no exista gradiente a propagar.
        </p>

        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L64-65&style=gruvbox-dark&showLineNumbers=on"></script>

        <div class="img-contenedor">
          <a href="https://imgur.com/flxLBtP"
            ><img
              src="https://i.imgur.com/flxLBtP.png"
              title="Función Tangente Hiperbólica"
          /></a>
          <p>Función Tangente Hiperbólica</p>
        </div>

        <h3 id="función-relu-rectified-linear-unit">
          Función ReLU (Rectified Linear Unit)
        </h3>
        <p>
          La función de activación ReLU, activa un nodo o neurona sólo si la
          entrada es mayor a $0$. Si la entrada es menor a $0$, entonces la
          salida es siempre $0$. Cuando la entrada es mayor a $0$, el nodo o
          neurona se activa, y la salida es una relación lineal con la variable
          de entrada de la forma $f(x) = x$.
        </p>
        $$ f(x)= max(0,x) $$
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L67-68&style=gruvbox-dark&showLineNumbers=on"></script>
        <div class="img-contenedor">
          <a href="https://imgur.com/MXtRkkS"
            ><img src="https://i.imgur.com/MXtRkkS.png" title="Función ReLU"
          /></a>
          <p>Función ReLU</p>
        </div>

        <p>
          Actualmente es muy utilizada debido a su buen funcionamiento para
          diferentes situaciones y problemas, teniendo incluso una tendencia a
          mejores entrenamientos para las capas ocultas que los realizados con
          la
          <em>función sigmoide</em> o <em>tanh</em>.
        </p>

        <p>
          Como una de sus principales contras, sufre de un problema conocido
          como
          <em>“dying ReLU”</em>. Este problema consiste en la <em>muerte</em> de
          algunas neuronas durante el entrenamiento, dado que su salida, debido
          a esta función de activación, es siempre 0 y por lo tanto no llega a
          activarse. Esto puede ocurrir cuando los pesos de una neurona son
          actualizados de modo que la suma ponderada de entradas y pesos
          asociados es siempre menor a $0$. Cuando esto pasa, la función de
          activación sólo genera como salida ceros, y el Gradiente Descendiente
          deja de tener efecto porque el gradiente de la función ReLU es cero
          cuando su entrada es negativa.
        </p>

        <h3 id="función-leaky-relu">Función Leaky ReLU</h3>
        <p>
          La función Leaky ReLU es una variante de la función de activación ReLU
          que viene a solucionar el problema conocido como
          <em>“dying ReLU”</em>. Para esto, en vez de tener una salida igual a 0
          para entradas menos a 0, esta función introduce una pequeña pendiente
          típica de $0.01$. Esta pequeña pendiente es posible usarla como otro
          <em>hiperparámetro</em> a sintonizar.
        </p>
        <p>Esta función está definida como:</p>
        $$ f(x)= max(0.01x,x) $$

        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L70-72&style=gruvbox-dark&showLineNumbers=on"></script>

        <div class="img-contenedor">
          <a href="https://imgur.com/wmH0Y3T"
            ><img
              src="https://i.imgur.com/wmH0Y3T.png"
              title="Función Leaky ReLU"
          /></a>
          <p>Función Leaky ReLU</p>
        </div>

        <p>
          El hiperparámetro <em>alpha</em> define la pendiente para la función
          cuando la entrada es $x&lt;0$. Esta pequeña pendiente asegura que aún
          cuando una situación como <em>“dying ReLU”</em> suceda, la salida no
          sea totalmente $0$, si no cercano a este, dejando siempre la
          posibilidad de una posible activación.
        </p>

        <br />
        <br />
        <br />
        <hr class="rounded" />
        <hr class="rounded" />
        <br />
        <br />
        <br />

        <h2 id="funciones-de-pérdida">Funciones de Pérdida</h2>
        <p>
          La función de pérdida, también conocida como
          <em>función de costo</em> o <em>función de error</em>, es una medida
          de <em>qué tan incorrecta</em> es una predicción de una red. Si esta
          pérdida es alta, el modelo no está haciendo un muy buen trabajo. Esto
          quiere decir que a <em>pérdida</em> más pequeña, mejor trabajo estará
          haciendo el modelo.
        </p>
        <ul>
          <li>
            <strong>¿Por qué se necesitan?</strong> porque el cálculo del error
            es un problema de optimización, y como tal, es necesario ajustar y
            optimizar sus parámetros para minimizar este el
            <em>error en la predicción</em>.
          </li>
        </ul>
        <p>
          Se definen en TensorFlow.js al momento de compilar el modelo en el
          &nbsp <code>model.compile({ }) </code> &nbsp mediante la etiqueta
          &nbsp
          <code>loss: </code>
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L74-78&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="mean-square-error-mse">Mean square error (MSE)</h3>
        <p>
          Es el error cuadrático medio entre las predicciones y los valores
          reales. Es comunmente usada en problemas de regresión que requiere
          como salida un valor continuo.
        </p>
        $$ MSE = \frac{1}{N} \sum_{i=1}^{n} (y_{i} - \hat{y_{i}})^2 $$
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L79-80&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE)</h3>
        <p>
          El error medio absoluto calcula cuan lejos está la predicción de su
          valor real, tomando el valor absoluto y retornando el valor promedio.
          Es recomendada en problemas de regresión.
        </p>
        $$ MAE = \frac{1}{N} \sum_{i=1}^{n} |y_{i}- \hat{y_{i}}| $$
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L82-83&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="binary-cross-entropy">Binary cross entropy</h3>
        <p>
          Es la función de pérdida recomendada para problemas de clasificación
          de dos clases.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L85-86&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="categorical-cross-entropy">Categorical cross entropy</h3>
        <p>
          Función de pérdida recomendada para problemas de clasificación de más
          de 2 clases.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L88-89&style=gruvbox-dark&showLineNumbers=on"></script>

        <br />
        <br />
        <br />
        <hr class="rounded" />
        <hr class="rounded" />
        <br />
        <br />
        <br />

        <h2 id="optimizadores">Optimizadores</h2>
        <p>
          Los optimizadores son algorítmos encargados de
          <em>encontrar</em> los pesos asociados que
          <em>minimicen la función de pérdida</em>. El algorítmo más popular es
          el Gradiente Descendiente que calcula el gradiente de la función de
          pérdida, para obtener la dirección de máximo crecimiento de la
          función, y así poder moverse en pequeños pasos en la dirección
          contraria. Cada <em>paso</em> o <em>step</em> dado en la dirección de
          mínimo crecimiento de la función de pérdida, es lo que se conoce como
          <strong>Learning Rate</strong> o <strong>Tasa de Aprendizaje</strong>.
        </p>
        <p>
          Se definen en TensorFlow.js al momento de compilar el modelo en el
          &nbsp <code>model.compile({ }) </code> &nbsp mediante la etiqueta
          &nbsp
          <code>optimizer </code>
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L74-78&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="stochastic-gradient-descent-sgd">
          Stochastic Gradient Descent (SGD)
        </h3>
        <p>
          El <em>optimizador más simple</em>. Usa siempre el Learning Rate (Tasa
          de aprendizaje) como el multiplicador para gradientes.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L19-21&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="momemtum">Momemtum</h3>
        <p>
          Acumula gradientes pasados de modo que la actulización de
          pesos-parámetros se hace más rápido si estos
          <em>gradiente pasados</em> se alinean con los
          <em>gradientes actualizados</em>. Si el gradiente comienza a cambiar
          mucho de dirección en cada actualización, la actualización de
          parámetros se ralentiza.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L23-25&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="rmsprop">RMSProp</h3>
        <p>
          Escala el factor multiplicativo de forma diferente para diferentes
          pesos-parámetros. Lo hace manteniendo un historial reciente del valor
          RMS (root mean square) de cada gradiente por peso.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L27-29&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="adadelta">AdaDelta</h3>
        <p>
          Tiene un comportamiento parecido a RMSprop, debido a que escala la
          tasa de aprendizaje de forma individual para cada peso-parámetro.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L31-33&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="adam">ADAM</h3>
        <p>
          El optimizador ADAM, es uno de los más utilizados, y puede ser
          entendido como una combinación entre una tasa de aprendizaje
          adaptativa como en AdaDelta y el método utilizado por el optimizador
          Momemtum.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L35-37&style=gruvbox-dark&showLineNumbers=on"></script>

        <h3 id="adamax">AdaMax</h3>
        <p>
          Es un optimizador similar a ADAM, que mantiene el rastro de las
          magnitudes de los gradientes.
        </p>
        <script src="https://emgithub.com/embed.js?target=https%3A%2F%2Fgithub.com%2Fccofres%2FplataformaJS%2Fblob%2Fmain%2Fsrc%2FdevJS%2FtfjsSnippets.js%23L39-41&style=gruvbox-dark&showLineNumbers=on"></script>
      </div>
    </div>
    <div class="control-buttons-down">
      <div class="control-buttons-up-left">
        <a href="../modelos.html" title="Modelos"> &#9776;Menú</a>
      </div>
      <div class="control-buttons-up-left">
        <a
          href="./01-breve-historia.html"
          title="Breve historia de la IA y el Aprendizaje Profundo"
        >
          &laquo;Back</a
        >
      </div>
      <div class="control-buttons-up-right">
        <a
          href="./20-intro-CNN.html"
          title="Introducción a las Redes Neuronales Convolucionales"
        >
          Next&raquo;
        </a>
      </div>
    </div>

    <!-- FOOTER -  PIE DE PAGINA-->
    <div id="the-footer">
      <footer>
        <p>Legal disclaimer, copyright, etc.</p>
        <ul>
          <li>
            <a href="#"
              ><img src="../../img/icon1.png" alt="Social Media 1."
            /></a>
          </li>
          <li>
            <a href="#"
              ><img src="../../img/icon2.png" alt="Social Media 2."
            /></a>
          </li>
        </ul>
      </footer>
    </div>
    <!-- SIDENAV -->
    <nav id="mySidenav" class="sidenav"></nav>
    <!-- FIN SideNav-->
    <!-- SCROLL BUTTON -->
    <button onclick="topFunction()" id="myBtn" title="Go to top">Up!</button>
    <!-- SCROLL BUTTON -->
    <script src="./load-mathjax.js"></script>
    <script src="../tensorflowjs/ui-sidebar.js"></script>
    <script src="../../ui-scrollButton.js"></script>
  </body>
</html>
